{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/BYHYKVoU9wfkUFO5tEh7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FGalvao77/-TUTORIAL---TensorFlow/blob/main/03_%5BTUTORIAL%5D_Como_carregar_dados_CSV_para_aplica%C3%A7%C3%A3o_no_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **03 - [TUTORIAL] Como carregar dados `CSV` para aplicação no _TensorFlow_**\n",
        "---\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "Este tutorial fornece um exemplo de como carregar dados CSV de um arquivo em um `tf.data.Dataset`.\n",
        "\n",
        "Os dados usados neste tutorial foram retirados da lista de passageiros do **Titanic88. O modelo preverá a probabilidade de sobrevivência de um passageiro com base em características como idade, sexo, classe de passagem e se a pessoa estava viajando sozinha.\n",
        "\n",
        "Material base de consulta e orientação:\n",
        "- https://www.tensorflow.org/tutorials/load_data/csv?hl=pt-br\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "xiV-4BQTn8uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. Setup**"
      ],
      "metadata": {
        "id": "CCUQbdDSoE9x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV2m5B4BnrAL",
        "outputId": "1ebd7038-6e80-4c9c-a782-5dcb6096cfb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # %tensorflow_version only exists in Colab\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "X4WGdCLQn3B_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    '[VERSION] -',\n",
        "    f'NumPy: {np.__version__} |',\n",
        "    f'TensorFlow: {tf.__version__}'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNdMeF9on2_L",
        "outputId": "beaeaa38-e845-44ae-bfdf-98a17bc3bb0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[VERSION] - NumPy: 1.21.6 | TensorFlow: 2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DATA_URL = 'https://storage.googleapis.com/tf-datasets/titanic/train.csv'\n",
        "\n",
        "TEST_DATA_URL = 'https://storage.googleapis.com/tf-datasets/titanic/eval.csv'"
      ],
      "metadata": {
        "id": "R_XbiL_lp0di"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_path = tf.keras.utils.get_file('train.csv', TRAIN_DATA_URL)\n",
        "\n",
        "test_file_path = tf.keras.utils.get_file('eval.csv', TEST_DATA_URL)"
      ],
      "metadata": {
        "id": "ykc9H_zyn29G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5c0f2e-7381-48b5-9437-6d9f643d6769"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
            "30874/30874 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
            "13049/13049 [==============================] - 0s 1us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setando o ambiente para facilitar a leitura de valores numpy\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "metadata": {
        "id": "-so2fuUan26n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. Carregar dados**"
      ],
      "metadata": {
        "id": "yD7L7YgeqHHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizando o conjunto de dados:\n",
        "- `head`: 10 primeiras observações e,\n",
        "- `tail`: 10 últimas observações."
      ],
      "metadata": {
        "id": "cF9k3SnowZN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head {train_file_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT8D86zvp6WF",
        "outputId": "1c2bb647-9a41-497e-d5db-b5466915de1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone\n",
            "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n",
            "1,female,38.0,1,0,71.2833,First,C,Cherbourg,n\n",
            "1,female,26.0,0,0,7.925,Third,unknown,Southampton,y\n",
            "1,female,35.0,1,0,53.1,First,C,Southampton,n\n",
            "0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y\n",
            "0,male,2.0,3,1,21.075,Third,unknown,Southampton,n\n",
            "1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n\n",
            "1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n\n",
            "1,female,4.0,1,1,16.7,Third,G,Southampton,n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail {train_file_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byuHzZf-w4HS",
        "outputId": "e52e59c9-8b81-4243-8672-b61b984f6b03"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1,female,15.0,0,0,7.225,Third,unknown,Cherbourg,y\n",
            "0,male,20.0,0,0,9.8458,Third,unknown,Southampton,y\n",
            "0,male,19.0,0,0,7.8958,Third,unknown,Southampton,y\n",
            "0,male,28.0,0,0,7.8958,Third,unknown,Southampton,y\n",
            "0,female,22.0,0,0,10.5167,Third,unknown,Southampton,y\n",
            "0,male,28.0,0,0,10.5,Second,unknown,Southampton,y\n",
            "0,male,25.0,0,0,7.05,Third,unknown,Southampton,y\n",
            "1,female,19.0,0,0,30.0,First,B,Southampton,y\n",
            "0,female,28.0,1,2,23.45,Third,unknown,Southampton,n\n",
            "0,male,32.0,0,0,7.75,Third,unknown,Queenstown,y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Você pode carregar isso usando pandas e passar as matrizes NumPy para o TensorFlow. Se você precisar escalar até um grande conjunto de arquivos ou precisar de um carregador que se integre ao TensorFlow e tf.data, use o `tf.data.experimental.make_csv_dataset`:\n",
        "\n",
        "A única coluna que você precisa identificar explicitamente é aquela com o valor que o modelo pretende prever."
      ],
      "metadata": {
        "id": "0yrAsWNtGkjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instanciando a coluna dependente\n",
        "LABEL_COLUMN = 'survived'\n",
        "\n",
        "# instanciando o valor do rótulo\n",
        "LABELS = [0, 1] # 0: não | 1: sim"
      ],
      "metadata": {
        "id": "W_ERO_vop6Sc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ?tf.data.experimental.make_csv_dataset"
      ],
      "metadata": {
        "id": "ktrLjtM-20Lx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(file_path:str, **kwargs) -> str:\n",
        "    dataset = tf.data.experimental.make_csv_dataset(\n",
        "        file_pattern=file_path,\n",
        "        batch_size=100, # utilizando somente 100 observações para análise\n",
        "        label_name=LABEL_COLUMN,\n",
        "        na_value='?',\n",
        "        num_epochs=1,\n",
        "        ignore_errors=True,\n",
        "        encoding='utf-8',\n",
        "        **kwargs\n",
        "    )\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "UMir4VH2p6Rj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_data = get_dataset(train_file_path)\n",
        "\n",
        "raw_test_data = get_dataset(test_file_path)"
      ],
      "metadata": {
        "id": "i9bpjx-Op6QE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e045dd-be58-4ff8-8358-6c109b19fa0f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/data/experimental/ops/readers.py:572: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.ignore_errors` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzJLmf3fp6Jv",
        "outputId": "4d3cea89-0779-490d-aa04-b63cfe69b22e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(OrderedDict([('sex', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('age', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('n_siblings_spouses', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('parch', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('fare', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('class', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('deck', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('embark_town', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('alone', TensorSpec(shape=(None,), dtype=tf.string, name=None))]), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNC6_K2xyuqM",
        "outputId": "686736d1-999d-426b-c56e-bb19313ad859"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(OrderedDict([('sex', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('age', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('n_siblings_spouses', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('parch', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('fare', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('class', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('deck', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('embark_town', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('alone', TensorSpec(shape=(None,), dtype=tf.string, name=None))]), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch(dataset:str) -> str:\n",
        "    for batch, label in dataset.take(1):\n",
        "        for key, value in batch.items():\n",
        "            print('{:20s}: {}'.format(key, value.numpy()))"
      ],
      "metadata": {
        "id": "2uzdH-vZp6H9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada item do conjunto de dados é um lote, representado como uma tupla de (* muitos exemplos *, * muitos rótulos *). Os dados dos exemplos são organizados em tensores baseados em colunas (em vez de tensores baseados em linhas), cada um com tantos elementos quanto o tamanho do lote (5 neste caso).\n",
        "\n",
        "Pode ajudar a ver isso por si mesmo."
      ],
      "metadata": {
        "id": "NBAZlgDlHIEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_batch(dataset=raw_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2st9fMQip6Ec",
        "outputId": "0ae9fead-094d-4ff2-873c-186676421138"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sex                 : [b'female' b'male' b'female' b'male' b'male' b'female' b'female' b'male'\n",
            " b'female' b'male' b'female' b'male' b'male' b'female' b'female' b'male'\n",
            " b'female' b'male' b'male' b'male' b'male' b'female' b'male' b'female'\n",
            " b'male' b'female' b'female' b'female' b'male' b'male' b'female' b'male'\n",
            " b'female' b'male' b'male' b'male' b'male' b'male' b'male' b'female'\n",
            " b'male' b'male' b'male' b'male' b'male' b'male' b'male' b'male' b'female'\n",
            " b'male' b'male' b'female' b'female' b'male' b'male' b'female' b'male'\n",
            " b'male' b'male' b'male' b'male' b'male' b'female' b'male' b'male'\n",
            " b'female' b'male' b'female' b'male' b'male' b'male' b'male' b'male'\n",
            " b'male' b'female' b'female' b'male' b'male' b'male' b'male' b'male'\n",
            " b'female' b'male' b'male' b'female' b'male' b'male' b'male' b'male'\n",
            " b'female' b'female' b'female' b'male' b'female' b'male' b'male' b'male'\n",
            " b'male' b'male' b'male']\n",
            "age                 : [60.  28.   4.  17.  20.  21.  30.  28.  52.  26.  23.  18.  45.  23.\n",
            " 24.  49.  28.  56.  46.  39.  28.  48.  34.  19.  36.  22.  40.  28.\n",
            " 28.  47.  14.  28.  17.  28.  27.  24.  21.  17.  28.  54.  18.  28.\n",
            " 40.  48.  23.  28.  52.  28.  28.  39.  28.  28.  28.  43.  29.  28.\n",
            " 51.  16.  70.5 22.  42.  30.5 28.  28.  20.  47.  60.  24.  40.  37.\n",
            " 30.   4.  28.  28.  22.   7.  33.   9.  30.  19.   1.  25.  65.  49.\n",
            " 28.  28.  33.  31.  29.  17.  50.  22.  28.  15.  28.  24.   9.  34.\n",
            " 44.  23. ]\n",
            "n_siblings_spouses  : [1 0 1 0 1 0 0 8 1 0 0 1 0 0 2 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 8 0 4 0 0 1 0 0 0 0 1 0 0 0 2 0 4 1 0\n",
            " 0 0 0 4 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0]\n",
            "parch               : [0 0 1 0 1 0 0 2 0 0 0 0 0 0 3 1 0 0 0 0 0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0\n",
            " 0 2 0 2 0 0 2 0 0 0 0 0 0 1 0 0 1 2 0 0 0 0 1 1 0 0]\n",
            "fare                : [ 75.25    7.896  23.      7.125  15.742   7.75    8.663  69.55   78.267\n",
            "   7.775  13.792   6.496   6.975   7.55   18.75  110.883   7.75   26.55\n",
            "  79.2    13.      7.796  65.      6.496  30.     13.     55.    153.462\n",
            "   7.229   7.05    9.     30.071   8.05   14.458   8.663   7.896   7.496\n",
            "   7.925   8.663   7.896  59.4     7.796  30.5    27.721  52.     10.5\n",
            "   7.55   30.5    39.6     7.733   0.     26.55   89.104  15.5     8.05\n",
            "   7.046  69.55    8.05   39.688   7.75    7.796  27.      8.05    7.75\n",
            "   7.75    8.05   14.5    26.55   69.3    31.      7.925   7.896  31.275\n",
            "  15.246   8.05   10.517  26.25   12.275  31.388   7.225   0.     20.575\n",
            "   7.925  26.55   89.104   7.896  13.      9.5    37.004  66.6    12.\n",
            "  26.     49.5     8.113   7.225   7.312   7.896  15.9    14.4     7.925\n",
            "  15.046]\n",
            "class               : [b'First' b'Third' b'Second' b'Third' b'Third' b'Third' b'Third' b'Third'\n",
            " b'First' b'Third' b'Second' b'Third' b'Third' b'Third' b'Second' b'First'\n",
            " b'Third' b'First' b'First' b'Second' b'Third' b'Second' b'Third' b'First'\n",
            " b'Second' b'First' b'First' b'Third' b'Third' b'Third' b'Second' b'Third'\n",
            " b'Third' b'Third' b'Third' b'Third' b'Third' b'Third' b'Third' b'First'\n",
            " b'Third' b'First' b'First' b'First' b'Second' b'Third' b'First' b'First'\n",
            " b'Third' b'First' b'First' b'First' b'Third' b'Third' b'Third' b'Third'\n",
            " b'Third' b'Third' b'Third' b'Third' b'Second' b'Third' b'Third' b'Third'\n",
            " b'Third' b'Third' b'First' b'First' b'First' b'Third' b'Third' b'Third'\n",
            " b'Third' b'Third' b'Third' b'Second' b'Second' b'Third' b'Third' b'Third'\n",
            " b'Third' b'Third' b'First' b'First' b'Third' b'Second' b'Third' b'Second'\n",
            " b'First' b'Second' b'Second' b'First' b'Third' b'Third' b'Third' b'Third'\n",
            " b'Third' b'Third' b'Third' b'Second']\n",
            "deck                : [b'D' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'D' b'unknown' b'D' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'C' b'unknown' b'unknown' b'B' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'B' b'unknown' b'E' b'C' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'C'\n",
            " b'unknown' b'C' b'unknown' b'unknown' b'C' b'unknown' b'unknown' b'A'\n",
            " b'unknown' b'C' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'B' b'A' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'E'\n",
            " b'C' b'unknown' b'unknown' b'unknown' b'unknown' b'C' b'unknown'\n",
            " b'unknown' b'B' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Cherbourg' b'Southampton' b'Southampton' b'Southampton' b'Cherbourg'\n",
            " b'Queenstown' b'Southampton' b'Southampton' b'Cherbourg' b'Southampton'\n",
            " b'Cherbourg' b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Cherbourg' b'Queenstown' b'Southampton' b'Cherbourg' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Cherbourg' b'Southampton'\n",
            " b'Southampton' b'Cherbourg' b'Southampton' b'Cherbourg' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Cherbourg' b'Southampton' b'Southampton' b'Cherbourg'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton' b'Cherbourg'\n",
            " b'Queenstown' b'Southampton' b'Southampton' b'Cherbourg' b'Queenstown'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Queenstown' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Queenstown' b'Queenstown' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Cherbourg' b'Cherbourg' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Cherbourg' b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Cherbourg' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Cherbourg' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Cherbourg' b'Southampton' b'Cherbourg' b'Southampton' b'Cherbourg'\n",
            " b'Southampton' b'Cherbourg' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Cherbourg']\n",
            "alone               : [b'n' b'y' b'n' b'y' b'n' b'y' b'y' b'n' b'n' b'y' b'y' b'n' b'y' b'y'\n",
            " b'n' b'n' b'y' b'y' b'y' b'y' b'y' b'n' b'y' b'y' b'y' b'n' b'y' b'y'\n",
            " b'y' b'y' b'n' b'y' b'y' b'y' b'y' b'y' b'y' b'y' b'y' b'n' b'y' b'y'\n",
            " b'y' b'n' b'y' b'y' b'y' b'y' b'y' b'y' b'y' b'n' b'n' b'y' b'n' b'n'\n",
            " b'y' b'n' b'y' b'y' b'n' b'y' b'y' b'y' b'y' b'n' b'y' b'y' b'y' b'n'\n",
            " b'y' b'n' b'n' b'y' b'y' b'n' b'y' b'n' b'y' b'y' b'n' b'n' b'y' b'n'\n",
            " b'y' b'y' b'y' b'n' b'n' b'y' b'n' b'n' b'y' b'y' b'y' b'y' b'n' b'n'\n",
            " b'y' b'y']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como você pode ver, as colunas no CSV são nomeadas. O construtor do conjunto de dados selecionará esses nomes automaticamente. Se o arquivo com o qual você está trabalhando não contém os nomes das colunas na primeira linha, passe-os em uma lista de strings para o argumento `column_names` na função `make_csv_dataset`."
      ],
      "metadata": {
        "id": "znPWXTzbHSho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_COLMUNS = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', \n",
        "               'fare', 'class', 'deck', 'embark_town', 'alone']"
      ],
      "metadata": {
        "id": "TEO0s6lep6Bw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dataset = get_dataset(\n",
        "    file_path=train_file_path,\n",
        "    column_names=CSV_COLMUNS\n",
        ")\n",
        "\n",
        "show_batch(dataset=temp_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DnrcZ_bn238",
        "outputId": "88003bb6-956e-4971-98ee-28c31b99f7d8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sex                 : [b'male' b'female' b'male' b'female' b'male' b'male' b'male' b'male'\n",
            " b'male' b'male' b'male' b'male' b'male' b'male' b'female' b'female'\n",
            " b'female' b'male' b'male' b'male' b'male' b'male' b'female' b'male'\n",
            " b'female' b'male' b'male' b'female' b'male' b'female' b'female' b'male'\n",
            " b'male' b'male' b'male' b'male' b'male' b'female' b'female' b'male'\n",
            " b'male' b'male' b'male' b'female' b'female' b'female' b'female' b'male'\n",
            " b'female' b'male' b'male' b'female' b'male' b'female' b'female' b'male'\n",
            " b'female' b'male' b'female' b'male' b'male' b'male' b'female' b'male'\n",
            " b'male' b'male' b'male' b'male' b'male' b'male' b'male' b'male' b'male'\n",
            " b'female' b'female' b'male' b'male' b'male' b'male' b'male' b'male'\n",
            " b'male' b'female' b'male' b'male' b'male' b'male' b'male' b'male' b'male'\n",
            " b'female' b'male' b'male' b'female' b'male' b'male' b'male' b'female'\n",
            " b'male' b'female']\n",
            "age                 : [49.   48.   26.   28.   48.   28.   28.   28.   28.   16.   33.   28.\n",
            " 31.   28.   24.   24.   28.   34.   28.   30.   31.   23.   27.   28.\n",
            " 50.   28.   32.   42.   28.   29.   24.   32.   28.   25.   28.   34.\n",
            " 28.   24.   31.   28.   70.5  46.   28.   22.   36.   28.   28.   28.\n",
            " 28.   18.   26.   52.   46.    2.   32.   36.   14.   24.    0.75 28.\n",
            " 62.   34.5  31.   14.   18.   24.   25.   28.    2.   47.   30.   23.\n",
            " 36.   45.   42.   11.   17.   45.   25.   30.   40.   23.   28.   40.5\n",
            " 49.   19.   28.   22.   19.   27.   39.   28.   28.   30.   25.   36.\n",
            " 28.   26.    0.83 24.  ]\n",
            "n_siblings_spouses  : [1 1 0 3 0 0 8 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 8 1 2 0 0 0 0 0 0\n",
            " 0 1 0 0 1 0 0 0 1 8 0 1 0 0 1 0 0 1 1 1 0 2 1 0 0 1 5 1 1 1 0 4 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 3 0 1 0 1 0 0 0 0 0 0 0]\n",
            "parch               : [1 0 0 1 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 2 1 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 2 2 0 2 0 0 0 0 1 0 1 1 2 2 1 1 0 0 0 0 2 1 0 0 0 1 0 0 1 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 5 0 0 0 0 1 0 0 2 2]\n",
            "fare                : [110.883  39.6     7.896  25.467   7.854   7.896  69.55    7.75    7.75\n",
            "  10.5    12.275  35.5    57.     30.696  65.     49.504   7.787   8.05\n",
            "  15.5     7.896  13.      7.896  11.133   7.896  10.5     0.     10.5\n",
            "  26.     69.55   10.462  18.75    7.896   7.896  13.      8.05    8.05\n",
            "   7.796  13.    113.275   9.5     7.75   61.175  26.55   49.5    71.\n",
            "  24.15   69.55    7.896  16.1     7.775  10.5    93.5    26.     10.462\n",
            "  15.5   120.    120.    247.521  19.258  24.15   10.5     6.438  18.\n",
            "  46.9     7.854  16.1    17.8     8.05   39.688  34.021  27.75   63.358\n",
            "  78.85   14.454  13.     18.788   8.663  26.55   13.      7.229   7.896\n",
            "  10.5    82.171   7.75   89.104   7.896   7.896   7.125 263.     30.5\n",
            "  31.275   7.725  15.85   56.929   7.742 512.329   8.458   7.925  29.\n",
            "  16.7  ]\n",
            "class               : [b'First' b'First' b'Third' b'Third' b'Third' b'Third' b'Third' b'Third'\n",
            " b'Third' b'Second' b'Second' b'First' b'First' b'First' b'Second'\n",
            " b'First' b'Third' b'Third' b'Third' b'Third' b'Second' b'Third' b'Third'\n",
            " b'Third' b'Second' b'Second' b'Second' b'Second' b'Third' b'Third'\n",
            " b'Second' b'Third' b'Third' b'Second' b'Third' b'Third' b'Third'\n",
            " b'Second' b'First' b'Third' b'Third' b'First' b'First' b'First' b'First'\n",
            " b'Third' b'Third' b'Third' b'Third' b'Third' b'Second' b'First' b'Second'\n",
            " b'Third' b'Third' b'First' b'First' b'First' b'Third' b'Third' b'Second'\n",
            " b'Third' b'Third' b'Third' b'Third' b'Third' b'Third' b'Third' b'Third'\n",
            " b'First' b'First' b'First' b'First' b'Third' b'Second' b'Third' b'Third'\n",
            " b'First' b'Second' b'Third' b'Third' b'Second' b'First' b'Third' b'First'\n",
            " b'Third' b'Third' b'Third' b'First' b'First' b'Third' b'Third' b'Third'\n",
            " b'First' b'Third' b'First' b'Third' b'Third' b'Second' b'Third']\n",
            "deck                : [b'C' b'A' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'C' b'B' b'unknown'\n",
            " b'unknown' b'C' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'G' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'F' b'D' b'unknown' b'unknown' b'E'\n",
            " b'C' b'B' b'B' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'B' b'unknown' b'G' b'unknown' b'B' b'B' b'B' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'D' b'C' b'D' b'C'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'C' b'unknown'\n",
            " b'unknown' b'unknown' b'C' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'E' b'unknown' b'B' b'unknown' b'unknown' b'unknown' b'G']\n",
            "embark_town         : [b'Cherbourg' b'Cherbourg' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Queenstown' b'Queenstown' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Cherbourg' b'Southampton'\n",
            " b'Cherbourg' b'Queenstown' b'Southampton' b'Queenstown' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Cherbourg' b'Southampton' b'Queenstown'\n",
            " b'Southampton' b'Southampton' b'Cherbourg' b'Southampton' b'Queenstown'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton' b'Queenstown'\n",
            " b'Southampton' b'Southampton' b'Cherbourg' b'Cherbourg' b'Queenstown'\n",
            " b'Southampton' b'Cherbourg' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Cherbourg' b'Cherbourg' b'Southampton' b'Cherbourg'\n",
            " b'Southampton' b'Cherbourg' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Cherbourg' b'Southampton' b'Southampton' b'Cherbourg' b'Queenstown'\n",
            " b'Cherbourg' b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Queenstown' b'Southampton' b'Cherbourg'\n",
            " b'Queenstown' b'Cherbourg' b'Queenstown' b'Southampton' b'Southampton'\n",
            " b'Southampton']\n",
            "alone               : [b'n' b'n' b'y' b'n' b'y' b'y' b'n' b'y' b'y' b'y' b'y' b'y' b'n' b'y'\n",
            " b'n' b'y' b'y' b'y' b'y' b'y' b'y' b'y' b'n' b'y' b'y' b'y' b'y' b'n'\n",
            " b'n' b'n' b'n' b'y' b'y' b'y' b'y' b'y' b'y' b'y' b'n' b'y' b'y' b'n'\n",
            " b'y' b'n' b'n' b'n' b'n' b'y' b'n' b'y' b'y' b'n' b'y' b'n' b'n' b'n'\n",
            " b'n' b'n' b'n' b'n' b'y' b'y' b'n' b'n' b'n' b'n' b'n' b'y' b'n' b'y'\n",
            " b'y' b'n' b'n' b'n' b'y' b'y' b'y' b'y' b'y' b'y' b'y' b'y' b'n' b'y'\n",
            " b'n' b'y' b'y' b'y' b'n' b'y' b'n' b'y' b'n' b'y' b'y' b'n' b'y' b'y'\n",
            " b'n' b'n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este exemplo vai usar todas as colunas disponíveis. Se você precisar omitir algumas colunas do conjunto de dados, crie uma lista apenas das colunas que planeja usar e passe-a para o argumento (opcional) `select_columns` do construtor."
      ],
      "metadata": {
        "id": "3f2ZaQ_CHdk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', \n",
        "                  'class', 'deck', 'alone']"
      ],
      "metadata": {
        "id": "AX1GXpU9n2uM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dataset = get_dataset(\n",
        "    file_path=train_file_path,\n",
        "    select_columns=SELECT_COLUMNS\n",
        ")\n",
        "\n",
        "show_batch(dataset=temp_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUx9BL2Y4cxd",
        "outputId": "04f72941-9917-406b-addc-7f525632e577"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age                 : [28.  19.  23.  47.  46.   7.  28.  29.  16.  23.  42.  40.  38.  25.\n",
            " 58.  28.  43.  50.  28.  14.  28.  42.  28.  21.  14.  18.  28.  19.\n",
            " 28.   3.  51.  18.  44.  28.  28.  24.   2.  30.  28.  24.  23.  22.\n",
            " 38.  19.  24.  28.  24.  58.  34.  28.  57.   4.  34.  45.  31.  29.\n",
            " 15.  31.  39.  40.  23.  35.  28.5 40.   6.  40.5 34.  21.  46.  64.\n",
            " 28.  32.  30.  47.  32.  28.  22.  51.   9.  39.  28.  28.  28.  18.\n",
            " 71.  18.   4.  41.  28.   1.  28.  24.  60.  28.  52.  28.  60.  10.\n",
            " 30.  37. ]\n",
            "n_siblings_spouses  : [0 0 0 1 1 0 0 0 0 3 0 1 0 0 0 0 0 1 0 1 0 1 0 2 5 1 2 0 0 1 0 0 0 0 8 0 4\n",
            " 1 1 2 0 0 1 0 0 1 0 0 0 8 0 4 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 4 0 0 0 0 0 0 0 0 0 1 5 0 0 0 0 1 0 1 3 0 1]\n",
            "class               : [b'Third' b'Third' b'Second' b'Third' b'First' b'Second' b'Third' b'Third'\n",
            " b'Third' b'First' b'Third' b'Third' b'First' b'Third' b'First' b'Third'\n",
            " b'Third' b'First' b'Third' b'Third' b'Third' b'First' b'Third' b'First'\n",
            " b'Third' b'Third' b'Third' b'Third' b'First' b'Second' b'First' b'Second'\n",
            " b'First' b'First' b'Third' b'Third' b'Third' b'Second' b'Second'\n",
            " b'Second' b'Third' b'First' b'Third' b'Third' b'First' b'First' b'First'\n",
            " b'First' b'Third' b'Third' b'Second' b'Third' b'Second' b'Third' b'First'\n",
            " b'Third' b'Third' b'Third' b'First' b'First' b'Third' b'Third' b'Third'\n",
            " b'Third' b'Third' b'Third' b'Second' b'Third' b'First' b'First' b'Third'\n",
            " b'Third' b'First' b'First' b'Third' b'Third' b'Third' b'Second' b'Third'\n",
            " b'Second' b'Third' b'Third' b'Third' b'Third' b'First' b'Third' b'Third'\n",
            " b'Third' b'First' b'Third' b'Third' b'Third' b'First' b'Third' b'First'\n",
            " b'Second' b'First' b'Third' b'First' b'Second']\n",
            "deck                : [b'unknown' b'unknown' b'D' b'unknown' b'E' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'C' b'unknown' b'unknown' b'C' b'F' b'B'\n",
            " b'unknown' b'unknown' b'C' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'B' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'F' b'E' b'unknown' b'B' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'F'\n",
            " b'C' b'B' b'C' b'C' b'unknown' b'unknown' b'unknown' b'unknown' b'F'\n",
            " b'unknown' b'B' b'unknown' b'unknown' b'unknown' b'E' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'E' b'unknown' b'unknown'\n",
            " b'unknown' b'B' b'C' b'unknown' b'unknown' b'unknown' b'E' b'E'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'A' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'B'\n",
            " b'unknown' b'B' b'unknown' b'unknown' b'unknown']\n",
            "alone               : [b'y' b'y' b'y' b'n' b'n' b'n' b'y' b'y' b'y' b'n' b'y' b'n' b'n' b'y'\n",
            " b'y' b'y' b'y' b'n' b'y' b'n' b'y' b'n' b'y' b'n' b'n' b'n' b'n' b'y'\n",
            " b'y' b'n' b'y' b'n' b'n' b'y' b'n' b'n' b'n' b'n' b'n' b'n' b'y' b'y'\n",
            " b'n' b'y' b'y' b'n' b'y' b'n' b'y' b'n' b'y' b'n' b'y' b'y' b'n' b'y'\n",
            " b'n' b'n' b'n' b'y' b'y' b'y' b'y' b'n' b'n' b'y' b'n' b'y' b'y' b'n'\n",
            " b'y' b'y' b'y' b'y' b'y' b'y' b'y' b'y' b'n' b'y' b'y' b'y' b'y' b'y'\n",
            " b'y' b'y' b'n' b'y' b'n' b'n' b'y' b'y' b'y' b'y' b'n' b'y' b'n' b'n'\n",
            " b'y' b'n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. Pré-processamento dos dados**"
      ],
      "metadata": {
        "id": "cUHFrrKy6dcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um arquivo CSV pode conter uma variedade de tipos de dados. Normalmente, você deseja converter desses tipos mistos em um vetor de comprimento fixo antes de alimentar os dados em seu modelo.\n",
        "\n",
        "O TensorFlow possui um sistema interno para descrever conversões de entrada comuns: `tf.feature_column`, consulte este tutorial para detalhes.\n",
        "\n",
        "Você pode pré-processar seus dados usando qualquer ferramenta que desejar (como nltk ou sklearn) e apenas passar a saída processada para o TensorFlow.\n",
        "\n",
        "A principal vantagem de fazer o pré-processamento dentro do seu modelo é que, quando você exporta o modelo, ele inclui o pré-processamento. Dessa forma, você pode passar os dados brutos diretamente para o seu modelo."
      ],
      "metadata": {
        "id": "Uz3u-W9sHwPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dados contínuos**\n",
        "\n",
        "Se seus dados já estiverem em um formato numérico apropriado, você poderá compactá-los em um vetor antes de transmiti-los ao modelo:"
      ],
      "metadata": {
        "id": "KHxcnyKsH6ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', \n",
        "                  'parch', 'fare']"
      ],
      "metadata": {
        "id": "Gb1Kcl2E4cwK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULTS = [0, 0.0, 0.0, 0.0, 0.0]"
      ],
      "metadata": {
        "id": "YyJKwuL14cuV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dataset = get_dataset(\n",
        "    file_path=train_file_path,\n",
        "    select_columns=SELECT_COLUMNS,\n",
        "    column_defaults=DEFAULTS\n",
        ")\n",
        "\n",
        "show_batch(dataset=temp_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaANymke4cqr",
        "outputId": "ac474624-b3d7-4a84-93de-8480d048d7fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age                 : [24.  23.  28.  50.  18.  70.5 63.  45.   9.  28.  39.  28.  31.  22.\n",
            " 45.  47.  28.  19.  40.  19.  32.5 28.  35.   5.  14.  42.  34.  64.\n",
            " 40.  27.  19.  28.  39.  28.  19.  28.  30.  16.  22.  59.  17.  24.\n",
            " 28.  28.  28.  28.  28.  22.  28.  24.  28.   2.  51.  28.  34.  27.\n",
            " 49.  18.  21.  25.  44.  18.  36.  44.  25.  28.  28.  21.  10.  29.\n",
            " 28.  28.  15.  28.  28.  32.   7.  28.  55.5 31.   4.   3.  28.  21.\n",
            " 31.  28.  28.  23.  40.5 19.  25.  39.  34.  16.  30.5 28.  66.  28.\n",
            " 44.  28. ]\n",
            "n_siblings_spouses  : [0. 0. 1. 1. 0. 0. 0. 0. 4. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 3. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 2. 1.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 2. 1. 1. 1. 0. 0. 1. 0. 0. 0. 3. 0. 0. 0.\n",
            " 1. 0. 0. 0. 4. 8. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            " 0. 0. 0. 1.]\n",
            "parch               : [1. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 4. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 4. 1. 2. 2. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 2. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 2. 0. 1. 5. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "fare                : [247.521  10.5    15.5   106.425   8.3     7.75    9.587   6.975  31.275\n",
            "  10.5    13.      8.05   26.25    7.25   83.475  34.021   7.896   8.05\n",
            "  27.9     7.896  13.      7.55   90.     12.475  30.071  26.     14.4\n",
            " 263.    134.5   211.5   263.     23.45    7.925  35.5    30.     13.\n",
            "   7.229   8.05   49.5    13.5     7.125  24.15    7.879   9.5     7.312\n",
            "   7.75   21.679  29.     26.      8.05   13.     12.288   8.05    8.05\n",
            "  21.     13.858   0.     17.8   262.375  91.079  26.      6.496  71.\n",
            "  57.979  26.      7.896  30.696  77.958  27.9     7.775   7.896 221.779\n",
            "  14.454   7.225   7.75    7.896  39.688  69.55    8.05   37.004  16.7\n",
            "  18.75    8.05   77.287  18.      7.25   13.     15.046  14.5    10.5\n",
            "  30.     31.275  13.      7.733   8.05   15.5    10.5     8.05    7.925\n",
            "  51.862]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch, labels_batch = next(iter(temp_dataset))"
      ],
      "metadata": {
        "id": "eKDi19NT4co-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui está uma função simples que agrupará todas as colunas:"
      ],
      "metadata": {
        "id": "9nlgczgaIA-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pack(features:str, label:str) -> str:\n",
        "    return tf.stack(list(features.values()), axis=1), label"
      ],
      "metadata": {
        "id": "Miww4bPT4cmH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplique isso a cada elemento do conjunto de dados:"
      ],
      "metadata": {
        "id": "6f0PMJ97IEFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "packed_dataset = temp_dataset.map(pack)\n",
        "\n",
        "for features, labels in packed_dataset.take(1):\n",
        "    print(features.numpy())\n",
        "    print()\n",
        "    print(labels.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxgUiSMM4ck4",
        "outputId": "d63b2858-26a3-46dc-85b9-028b41ce68d7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 28.      3.      1.     25.467]\n",
            " [ 22.      1.      0.      7.25 ]\n",
            " [ 22.      1.      1.     29.   ]\n",
            " [ 18.      0.      0.      9.842]\n",
            " [ 36.      1.      0.     15.55 ]\n",
            " [ 28.      8.      2.     69.55 ]\n",
            " [ 30.5     0.      0.      8.05 ]\n",
            " [ 42.      0.      0.      7.55 ]\n",
            " [ 28.      1.      0.     19.967]\n",
            " [ 32.      0.      0.      7.854]\n",
            " [ 28.      0.      0.     47.1  ]\n",
            " [ 33.      0.      0.     12.275]\n",
            " [ 28.      0.      0.      0.   ]\n",
            " [ 42.      0.      0.    227.525]\n",
            " [ 28.      0.      0.      8.05 ]\n",
            " [ 29.      0.      0.      9.5  ]\n",
            " [  2.      0.      1.     12.288]\n",
            " [  9.      5.      2.     46.9  ]\n",
            " [ 41.      0.      0.      7.125]\n",
            " [  5.      2.      1.     19.258]\n",
            " [ 45.      1.      1.    164.867]\n",
            " [ 29.      1.      0.     27.721]\n",
            " [ 17.      0.      0.      8.663]\n",
            " [ 26.      0.      0.      8.05 ]\n",
            " [ 21.      0.      1.     77.287]\n",
            " [ 28.      0.      0.     35.5  ]\n",
            " [ 48.      1.      2.     65.   ]\n",
            " [ 23.      0.      0.     13.   ]\n",
            " [ 32.      0.      0.      7.925]\n",
            " [  9.      4.      2.     31.388]\n",
            " [ 39.      0.      0.      0.   ]\n",
            " [ 31.      1.      1.     26.25 ]\n",
            " [ 28.      0.      0.      7.75 ]\n",
            " [ 21.      0.      0.      7.75 ]\n",
            " [  5.      0.      0.     12.475]\n",
            " [ 28.      0.      0.     29.7  ]\n",
            " [ 22.      0.      0.      7.25 ]\n",
            " [ 49.      0.      0.      0.   ]\n",
            " [ 54.      1.      0.     59.4  ]\n",
            " [ 39.      0.      0.     13.   ]\n",
            " [ 49.      1.      0.     56.929]\n",
            " [ 41.      0.      5.     39.688]\n",
            " [ 24.      1.      0.     26.   ]\n",
            " [ 23.      0.      0.      7.925]\n",
            " [ 57.      0.      0.     10.5  ]\n",
            " [ 20.      0.      0.      9.225]\n",
            " [ 28.      0.      0.      8.05 ]\n",
            " [ 25.      0.      0.      0.   ]\n",
            " [ 16.      0.      0.      7.75 ]\n",
            " [ 28.      0.      0.    110.883]\n",
            " [ 28.      0.      0.      7.879]\n",
            " [ 40.      1.      0.      9.475]\n",
            " [  4.      3.      2.     27.9  ]\n",
            " [ 16.      4.      1.     39.688]\n",
            " [ 28.      0.      0.      7.75 ]\n",
            " [ 58.      0.      0.     29.7  ]\n",
            " [ 28.      0.      0.     30.5  ]\n",
            " [ 29.      1.      0.     66.6  ]\n",
            " [ 51.      0.      0.     26.55 ]\n",
            " [ 36.      1.      2.    120.   ]\n",
            " [ 28.      0.      0.     13.   ]\n",
            " [ 48.      0.      0.     26.55 ]\n",
            " [ 52.      0.      0.     30.5  ]\n",
            " [ 48.      0.      0.      7.854]\n",
            " [ 19.      3.      2.    263.   ]\n",
            " [ 24.      0.      0.     83.158]\n",
            " [ 28.      0.      0.      7.729]\n",
            " [  7.      0.      2.     26.25 ]\n",
            " [ 25.      1.      0.      7.775]\n",
            " [ 28.      0.      0.      7.775]\n",
            " [ 28.      0.      0.     39.6  ]\n",
            " [ 29.      0.      0.      9.483]\n",
            " [ 32.      1.      1.     15.5  ]\n",
            " [ 19.      0.      0.     30.   ]\n",
            " [ 42.      0.      0.     13.   ]\n",
            " [ 44.      0.      1.     16.1  ]\n",
            " [ 24.      0.      3.     19.258]\n",
            " [ 17.      0.      0.     12.   ]\n",
            " [ 62.      0.      0.     10.5  ]\n",
            " [ 28.      1.      0.    133.65 ]\n",
            " [ 11.      5.      2.     46.9  ]\n",
            " [ 28.      0.      1.     33.   ]\n",
            " [ 22.      0.      2.     49.5  ]\n",
            " [ 46.      0.      0.     26.   ]\n",
            " [ 23.      0.      0.     15.046]\n",
            " [ 35.      0.      0.     26.55 ]\n",
            " [ 48.      1.      0.     52.   ]\n",
            " [ 22.      0.      0.      7.125]\n",
            " [ 18.      0.      0.      7.796]\n",
            " [  2.      4.      1.     39.688]\n",
            " [ 36.      1.      2.     27.75 ]\n",
            " [ 28.      0.      0.      7.896]\n",
            " [ 23.      1.      0.    113.275]\n",
            " [ 40.5     0.      2.     14.5  ]\n",
            " [ 14.      1.      2.    120.   ]\n",
            " [ 24.      0.      0.     79.2  ]\n",
            " [ 40.      1.      1.    134.5  ]\n",
            " [ 47.      0.      0.     34.021]\n",
            " [ 28.      0.      0.      7.879]\n",
            " [ 28.      0.      0.      7.896]]\n",
            "\n",
            "[0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0\n",
            " 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
            " 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se você tiver tipos de dados mistos, poderá separar esses campos numéricos simples. A API `tf.feature_column` pode lidar com eles, mas isso gera alguma sobrecarga e deve ser evitado, a menos que seja realmente necessário. Volte para o conjunto de dados misto:"
      ],
      "metadata": {
        "id": "6Jh-On-YIIWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_batch(raw_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuzUNa264cjf",
        "outputId": "74230d92-c4a5-4dbf-c3a4-a2346061a522"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sex                 : [b'male' b'male' b'male' b'male' b'male' b'female' b'female' b'male'\n",
            " b'male' b'male' b'female' b'male' b'male' b'female' b'female' b'male'\n",
            " b'male' b'male' b'male' b'male' b'male' b'male' b'female' b'male'\n",
            " b'female' b'female' b'male' b'male' b'female' b'male' b'male' b'male'\n",
            " b'male' b'male' b'male' b'female' b'female' b'male' b'male' b'male'\n",
            " b'male' b'male' b'male' b'male' b'male' b'female' b'male' b'male' b'male'\n",
            " b'male' b'male' b'male' b'male' b'male' b'female' b'female' b'male'\n",
            " b'female' b'male' b'female' b'female' b'male' b'male' b'male' b'male'\n",
            " b'male' b'female' b'female' b'female' b'female' b'female' b'male' b'male'\n",
            " b'female' b'female' b'female' b'male' b'male' b'female' b'female' b'male'\n",
            " b'female' b'male' b'male' b'male' b'male' b'male' b'male' b'female'\n",
            " b'male' b'male' b'male' b'male' b'female' b'female' b'male' b'female'\n",
            " b'female' b'male' b'male']\n",
            "age                 : [28.   27.   34.   70.   36.   28.   28.   39.   16.   28.   38.   30.\n",
            "  4.    0.75 44.   32.    4.    6.   35.   28.   22.   28.    9.   28.\n",
            " 16.   24.    9.   17.   14.   28.   37.   32.   37.    0.83 59.    0.75\n",
            " 28.   18.   19.    2.   24.   52.   28.   25.   42.   28.   22.   22.\n",
            "  4.   28.   16.   19.   29.   18.   28.   25.   40.5   2.   28.   50.\n",
            " 26.   28.   70.5   1.   28.   27.   40.   28.   28.   19.   28.   24.\n",
            " 28.   22.   40.   18.   28.   18.   26.    9.   28.    3.   47.   40.\n",
            " 28.   28.   28.   44.   54.   47.   28.   28.   51.   21.   28.   19.\n",
            " 30.   28.   45.   20.  ]\n",
            "n_siblings_spouses  : [0 1 0 1 0 1 2 0 0 0 0 0 1 2 0 0 4 0 0 0 0 0 4 0 0 0 1 1 1 8 2 1 1 0 0 2 0\n",
            " 1 0 4 0 0 0 0 0 1 0 0 4 0 4 0 1 0 0 1 0 0 0 0 0 0 0 4 0 0 1 0 8 0 1 1 0 0\n",
            " 1 0 0 1 0 3 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1]\n",
            "parch               : [0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 2 0 0 0 1 1 0 2 0 0 0 2 0 1 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 2 0 1 0 1 0 0 0 1 0 0 1 0 2 0 0 0 0 0\n",
            " 1 1 0 1 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "fare                : [ 56.496  53.1     6.496  71.      7.896  15.5    23.25   13.     10.5\n",
            "   7.775  13.     13.     11.133  19.258  27.721   7.854  29.125  12.475\n",
            "  26.288   7.25    8.05    7.896  31.275   7.896   7.733  83.158  15.9\n",
            "   7.229  11.242  69.55    7.925  15.85   53.1    29.      7.25   19.258\n",
            "  12.35  108.9    10.5    39.688   7.896  30.5     9.5     0.      7.55\n",
            "  24.      7.25    7.896  31.275   7.896  39.688   0.     27.721  13.\n",
            "   7.229 151.55    7.75   12.288   0.     26.      7.925   7.75    7.75\n",
            "  39.688   8.05   26.     39.      7.879  69.55   30.    133.65   16.1\n",
            "   7.896 151.55  134.5    23.      7.05   20.212  78.85   27.9    26.55\n",
            "  41.579  15.     31.      7.25    7.55   14.5    26.     59.4    38.5\n",
            "   7.729   8.05   12.525  77.958  79.2    10.171   8.663   7.55   35.5\n",
            "  15.742]\n",
            "class               : [b'Third' b'First' b'Third' b'First' b'Third' b'Third' b'Third' b'Second'\n",
            " b'Second' b'Third' b'Second' b'Second' b'Third' b'Third' b'First'\n",
            " b'Third' b'Third' b'Third' b'First' b'Third' b'Third' b'Third' b'Third'\n",
            " b'Third' b'Third' b'First' b'Third' b'Third' b'Third' b'Third' b'Third'\n",
            " b'Third' b'First' b'Second' b'Third' b'Third' b'Second' b'First'\n",
            " b'Second' b'Third' b'Third' b'First' b'Third' b'Third' b'Third' b'Second'\n",
            " b'Third' b'Third' b'Third' b'Third' b'Third' b'Third' b'Second' b'Second'\n",
            " b'Third' b'First' b'Third' b'Third' b'Second' b'Second' b'Third' b'Third'\n",
            " b'Third' b'Third' b'Third' b'Second' b'Second' b'Third' b'Third' b'First'\n",
            " b'First' b'Third' b'Third' b'First' b'First' b'Second' b'Third' b'Third'\n",
            " b'First' b'Third' b'First' b'Second' b'Second' b'First' b'Third' b'Third'\n",
            " b'Third' b'Second' b'First' b'First' b'Third' b'Third' b'Second' b'First'\n",
            " b'First' b'Third' b'Third' b'Third' b'First' b'Third']\n",
            "deck                : [b'unknown' b'E' b'unknown' b'B' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'B' b'unknown' b'unknown' b'E' b'E' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'C' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'C' b'unknown' b'unknown'\n",
            " b'unknown' b'E' b'C' b'unknown' b'unknown' b'unknown' b'C' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'C'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'B' b'unknown' b'unknown' b'unknown' b'unknown' b'E'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'C' b'unknown'\n",
            " b'unknown' b'A' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'E' b'unknown' b'unknown' b'unknown' b'D' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Queenstown' b'Queenstown' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton' b'Cherbourg'\n",
            " b'Cherbourg' b'Southampton' b'Queenstown' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Queenstown' b'Cherbourg' b'Southampton' b'Cherbourg'\n",
            " b'Cherbourg' b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Cherbourg' b'Queenstown' b'Cherbourg'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Cherbourg' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Cherbourg' b'Southampton' b'Cherbourg' b'Southampton'\n",
            " b'Queenstown' b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Queenstown' b'Queenstown' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Queenstown' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Cherbourg' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Cherbourg' b'Southampton' b'Cherbourg' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Cherbourg' b'Southampton'\n",
            " b'Queenstown' b'Southampton' b'Southampton' b'Southampton' b'Cherbourg'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton' b'Cherbourg']\n",
            "alone               : [b'y' b'n' b'y' b'n' b'y' b'n' b'n' b'y' b'y' b'y' b'y' b'y' b'n' b'n'\n",
            " b'y' b'y' b'n' b'n' b'y' b'y' b'y' b'y' b'n' b'y' b'y' b'y' b'n' b'n'\n",
            " b'n' b'n' b'n' b'n' b'n' b'n' b'y' b'n' b'y' b'n' b'y' b'n' b'y' b'y'\n",
            " b'y' b'y' b'y' b'n' b'y' b'y' b'n' b'y' b'n' b'y' b'n' b'y' b'y' b'n'\n",
            " b'y' b'n' b'y' b'n' b'y' b'y' b'y' b'n' b'y' b'y' b'n' b'y' b'n' b'y'\n",
            " b'n' b'n' b'y' b'y' b'n' b'n' b'y' b'n' b'y' b'n' b'y' b'n' b'y' b'y'\n",
            " b'y' b'y' b'y' b'n' b'n' b'y' b'y' b'y' b'y' b'y' b'y' b'y' b'y' b'y'\n",
            " b'y' b'n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch, labels_batch = next(iter(temp_dataset))"
      ],
      "metadata": {
        "id": "I4BNM7N64ch9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Portanto, defina um _pré-processador_ mais geral que selecione uma lista de recursos numéricos e os agrupe em uma única coluna:"
      ],
      "metadata": {
        "id": "wF2ugWNEIRWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PackNumericFeatures(object):\n",
        "    def __init__(self, names:str):\n",
        "        self.names = names\n",
        "\n",
        "    def __call__(self, features:str, labels:str):\n",
        "        numeric_features = [features.pop(name) for name in self.names]\n",
        "        numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "        numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "\n",
        "        features['numeric'] = numeric_features\n",
        "        return features, labels"
      ],
      "metadata": {
        "id": "jwIsOrDQ4cb3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUMERIC_FEATURES = ['age', 'n_siblings_spouses', 'parch', 'fare']\n",
        "\n",
        "packed_train_data = raw_train_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES)\n",
        ")\n",
        "\n",
        "packed_test_data = raw_test_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES)\n",
        ")"
      ],
      "metadata": {
        "id": "8H69XCQp4cY-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_batch(packed_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRWJ8esmp-9w",
        "outputId": "39e6fc13-feed-4fde-b8da-515269d480a0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sex                 : [b'male' b'male' b'female' b'female' b'male' b'male' b'female' b'male'\n",
            " b'female' b'male' b'male' b'female' b'female' b'female' b'male' b'male'\n",
            " b'female' b'male' b'male' b'female' b'male' b'female' b'male' b'male'\n",
            " b'male' b'female' b'female' b'male' b'male' b'male' b'male' b'male'\n",
            " b'female' b'female' b'female' b'female' b'female' b'male' b'male' b'male'\n",
            " b'male' b'male' b'female' b'male' b'female' b'male' b'male' b'male'\n",
            " b'male' b'male' b'female' b'male' b'female' b'female' b'female' b'male'\n",
            " b'male' b'female' b'female' b'male' b'male' b'male' b'male' b'male'\n",
            " b'male' b'male' b'female' b'male' b'male' b'male' b'female' b'male'\n",
            " b'female' b'male' b'male' b'male' b'male' b'female' b'male' b'male'\n",
            " b'female' b'male' b'male' b'female' b'female' b'female' b'female'\n",
            " b'female' b'female' b'male' b'female' b'male' b'male' b'male' b'female'\n",
            " b'male' b'male' b'female' b'male' b'male']\n",
            "class               : [b'Third' b'Third' b'Third' b'Third' b'Third' b'Third' b'Third' b'Third'\n",
            " b'Second' b'Third' b'First' b'First' b'First' b'First' b'Second' b'First'\n",
            " b'Third' b'Third' b'Third' b'First' b'Third' b'Second' b'Third' b'Third'\n",
            " b'Second' b'Second' b'Second' b'Third' b'Third' b'Second' b'Third'\n",
            " b'First' b'Second' b'First' b'Second' b'First' b'First' b'Third' b'Third'\n",
            " b'Third' b'Third' b'Third' b'Third' b'First' b'Third' b'Third' b'Second'\n",
            " b'First' b'First' b'First' b'Third' b'Second' b'Third' b'Third' b'Second'\n",
            " b'Third' b'Third' b'First' b'First' b'Third' b'Third' b'Second' b'Third'\n",
            " b'Third' b'Third' b'Second' b'Second' b'Third' b'Third' b'Third'\n",
            " b'Second' b'Third' b'Third' b'First' b'Third' b'Third' b'Third' b'Third'\n",
            " b'Third' b'Third' b'Third' b'Second' b'Third' b'Second' b'First' b'First'\n",
            " b'First' b'Third' b'First' b'Third' b'First' b'Third' b'Third' b'Third'\n",
            " b'Third' b'Third' b'Second' b'Third' b'Third' b'Third']\n",
            "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'C' b'B' b'unknown' b'C'\n",
            " b'unknown' b'E' b'unknown' b'unknown' b'unknown' b'B' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'C'\n",
            " b'unknown' b'B' b'C' b'unknown' b'F' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'A' b'unknown' b'F' b'unknown' b'C' b'D' b'B' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'B'\n",
            " b'C' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'E' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'B'\n",
            " b'B' b'D' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown' b'unknown' b'unknown' b'unknown' b'unknown'\n",
            " b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Cherbourg' b'Southampton' b'Cherbourg'\n",
            " b'Southampton' b'Queenstown' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Cherbourg' b'Southampton' b'Cherbourg' b'Cherbourg' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Queenstown' b'Southampton' b'Cherbourg'\n",
            " b'Southampton' b'Cherbourg' b'Southampton' b'Cherbourg' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Queenstown' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Cherbourg' b'Queenstown'\n",
            " b'Cherbourg' b'Cherbourg' b'Southampton' b'Cherbourg' b'Queenstown'\n",
            " b'Cherbourg' b'Cherbourg' b'Cherbourg' b'Queenstown' b'Cherbourg'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Cherbourg' b'Cherbourg'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Cherbourg' b'Southampton' b'Queenstown'\n",
            " b'Southampton' b'Southampton' b'Cherbourg' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Queenstown' b'Southampton' b'Cherbourg'\n",
            " b'Cherbourg' b'Cherbourg' b'Southampton' b'Cherbourg' b'Southampton'\n",
            " b'Cherbourg' b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton' b'Southampton' b'Southampton' b'Southampton' b'Queenstown']\n",
            "alone               : [b'n' b'y' b'y' b'n' b'y' b'n' b'y' b'y' b'y' b'y' b'n' b'n' b'y' b'n'\n",
            " b'n' b'y' b'n' b'y' b'y' b'n' b'y' b'n' b'n' b'y' b'y' b'y' b'y' b'y'\n",
            " b'y' b'y' b'n' b'y' b'n' b'y' b'n' b'n' b'n' b'y' b'y' b'n' b'n' b'y'\n",
            " b'y' b'y' b'n' b'y' b'y' b'y' b'n' b'y' b'y' b'y' b'n' b'n' b'n' b'y'\n",
            " b'y' b'n' b'y' b'y' b'n' b'y' b'y' b'y' b'y' b'n' b'n' b'y' b'n' b'y'\n",
            " b'y' b'n' b'n' b'y' b'y' b'y' b'y' b'n' b'n' b'n' b'n' b'y' b'n' b'n'\n",
            " b'y' b'n' b'n' b'y' b'y' b'y' b'y' b'y' b'y' b'n' b'y' b'y' b'n' b'n'\n",
            " b'y' b'n']\n",
            "numeric             : [[  1.      5.      2.     46.9  ]\n",
            " [ 17.      0.      0.      8.663]\n",
            " [ 15.      0.      0.      7.225]\n",
            " [ 28.      3.      1.     25.467]\n",
            " [ 20.      0.      0.      7.229]\n",
            " [ 18.      1.      1.     20.212]\n",
            " [ 28.      0.      0.      7.75 ]\n",
            " [ 44.      0.      0.      7.925]\n",
            " [ 28.      0.      0.     13.   ]\n",
            " [ 26.      0.      0.     56.496]\n",
            " [ 50.      1.      0.    106.425]\n",
            " [ 52.      1.      1.     93.5  ]\n",
            " [ 28.      0.      0.    110.883]\n",
            " [ 38.      1.      0.     71.283]\n",
            " [  3.      1.      1.     18.75 ]\n",
            " [ 36.      0.      0.     26.388]\n",
            " [ 11.      4.      2.     31.275]\n",
            " [ 22.      0.      0.      9.   ]\n",
            " [ 25.      0.      0.      7.05 ]\n",
            " [ 17.      1.      0.     57.   ]\n",
            " [ 19.      0.      0.      7.896]\n",
            " [ 50.      0.      1.     26.   ]\n",
            " [  9.      5.      2.     46.9  ]\n",
            " [ 45.      0.      0.      6.975]\n",
            " [ 35.      0.      0.     10.5  ]\n",
            " [ 28.      0.      0.     33.   ]\n",
            " [ 32.      0.      0.     13.   ]\n",
            " [ 19.      0.      0.      8.158]\n",
            " [ 16.      0.      0.      9.5  ]\n",
            " [ 57.      0.      0.     12.35 ]\n",
            " [ 24.      2.      0.     24.15 ]\n",
            " [ 71.      0.      0.     49.504]\n",
            " [ 22.      1.      1.     29.   ]\n",
            " [ 24.      0.      0.     49.504]\n",
            " [ 45.      1.      1.     26.25 ]\n",
            " [ 22.      0.      2.     49.5  ]\n",
            " [ 35.      1.      0.     53.1  ]\n",
            " [ 35.      0.      0.      8.05 ]\n",
            " [ 25.      0.      0.      7.65 ]\n",
            " [ 44.      0.      1.     16.1  ]\n",
            " [ 37.      2.      0.      7.925]\n",
            " [ 19.      0.      0.      0.   ]\n",
            " [ 28.      0.      0.      7.879]\n",
            " [ 28.      0.      0.     26.   ]\n",
            " [ 31.      1.      1.     20.525]\n",
            " [ 19.      0.      0.      7.65 ]\n",
            " [ 33.      0.      0.     12.275]\n",
            " [ 52.      0.      0.     30.5  ]\n",
            " [ 21.      0.      1.     77.287]\n",
            " [ 35.      0.      0.    512.329]\n",
            " [ 28.      0.      0.      7.787]\n",
            " [ 28.      0.      0.     15.05 ]\n",
            " [ 15.      1.      0.     14.454]\n",
            " [ 28.      3.      1.     25.467]\n",
            " [ 22.      1.      2.     41.579]\n",
            " [ 28.      0.      0.      7.75 ]\n",
            " [ 28.      0.      0.      7.229]\n",
            " [ 28.      1.      0.    146.521]\n",
            " [ 24.      0.      0.     83.158]\n",
            " [ 28.      0.      0.      7.75 ]\n",
            " [ 28.      1.      1.     15.246]\n",
            " [ 23.      0.      0.     10.5  ]\n",
            " [ 38.      0.      0.      7.05 ]\n",
            " [ 18.      0.      0.      7.75 ]\n",
            " [ 28.      0.      0.      7.896]\n",
            " [ 31.      1.      1.     37.004]\n",
            " [ 41.      0.      1.     19.5  ]\n",
            " [ 42.      0.      0.      7.55 ]\n",
            " [ 36.      1.      1.     24.15 ]\n",
            " [ 27.      0.      0.      8.663]\n",
            " [ 34.      0.      0.     13.   ]\n",
            " [ 14.      5.      2.     46.9  ]\n",
            " [ 24.      0.      3.     19.258]\n",
            " [ 47.      0.      0.     25.587]\n",
            " [ 28.      0.      0.      7.75 ]\n",
            " [ 25.      0.      0.      7.05 ]\n",
            " [ 28.      0.      0.      7.312]\n",
            " [ 28.      0.      2.     15.246]\n",
            " [ 41.      2.      0.     14.108]\n",
            " [  4.      1.      1.     11.133]\n",
            " [ 28.      1.      0.     16.1  ]\n",
            " [ 39.      0.      0.     26.   ]\n",
            " [ 28.      1.      0.     24.15 ]\n",
            " [  7.      0.      2.     26.25 ]\n",
            " [ 24.      0.      0.     69.3  ]\n",
            " [ 18.      2.      2.    262.375]\n",
            " [ 52.      1.      0.     78.267]\n",
            " [ 63.      0.      0.      9.587]\n",
            " [ 30.      0.      0.     31.   ]\n",
            " [ 28.      0.      0.     14.5  ]\n",
            " [ 30.      0.      0.    106.425]\n",
            " [ 25.      0.      0.      0.   ]\n",
            " [ 32.      0.      0.     56.496]\n",
            " [  2.      3.      1.     21.075]\n",
            " [ 28.      0.      0.      7.55 ]\n",
            " [ 35.      0.      0.      7.05 ]\n",
            " [  0.83    0.      2.     29.   ]\n",
            " [ 31.      1.      0.     18.   ]\n",
            " [ 28.      0.      0.      8.663]\n",
            " [  2.      4.      1.     29.125]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch, labels_batch = next(iter(packed_train_data))"
      ],
      "metadata": {
        "id": "JM1OgEHDp-5q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalização dos dados**\n",
        "\n",
        "Dados contínuos sempre devem ser normalizados."
      ],
      "metadata": {
        "id": "KhjscT8oEt3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2ObBh9fGp-2r"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desc = pd.read_csv(filepath_or_buffer=train_file_path)[NUMERIC_FEATURES].describe()"
      ],
      "metadata": {
        "id": "CFj9sTgLp-1U"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desc.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "56GYMMEKp-yw",
        "outputId": "67fe6275-c86b-4824-daf0-fd7622a5145f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    count       mean        std   min      25%      50%  \\\n",
              "age                 627.0  29.631308  12.511818  0.75  23.0000  28.0000   \n",
              "n_siblings_spouses  627.0   0.545455   1.151090  0.00   0.0000   0.0000   \n",
              "parch               627.0   0.379585   0.792999  0.00   0.0000   0.0000   \n",
              "fare                627.0  34.385399  54.597730  0.00   7.8958  15.0458   \n",
              "\n",
              "                        75%       max  \n",
              "age                 35.0000   80.0000  \n",
              "n_siblings_spouses   1.0000    8.0000  \n",
              "parch                0.0000    5.0000  \n",
              "fare                31.3875  512.3292  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49b4739d-82a2-4463-b1df-645d31f26b9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>627.0</td>\n",
              "      <td>29.631308</td>\n",
              "      <td>12.511818</td>\n",
              "      <td>0.75</td>\n",
              "      <td>23.0000</td>\n",
              "      <td>28.0000</td>\n",
              "      <td>35.0000</td>\n",
              "      <td>80.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <td>627.0</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>1.151090</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>8.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parch</th>\n",
              "      <td>627.0</td>\n",
              "      <td>0.379585</td>\n",
              "      <td>0.792999</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>5.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fare</th>\n",
              "      <td>627.0</td>\n",
              "      <td>34.385399</td>\n",
              "      <td>54.597730</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7.8958</td>\n",
              "      <td>15.0458</td>\n",
              "      <td>31.3875</td>\n",
              "      <td>512.3292</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49b4739d-82a2-4463-b1df-645d31f26b9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49b4739d-82a2-4463-b1df-645d31f26b9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49b4739d-82a2-4463-b1df-645d31f26b9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MEAN = np.array(desc.T['mean'])\n",
        "\n",
        "STD = np.array(desc.T['std'])"
      ],
      "metadata": {
        "id": "6iewO0CEp-xo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MEAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rRclggAp-wd",
        "outputId": "bc4eead3-d41e-47c8-f71b-25638495ea1e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29.631,  0.545,  0.38 , 34.385])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4FhNqPrp-q3",
        "outputId": "55ba0adf-95d7-49c0-c1d0-27b81264e6c2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12.512,  1.151,  0.793, 54.598])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_numeric_data(data:str, mean:eval, std:eval):\n",
        "    return (data-mean) / std"
      ],
      "metadata": {
        "id": "BlvQ6h6Ip-nm"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora crie uma coluna numérica. A API `tf.feature_columns.numeric_column` aceita um argumento `normalizer_fn`, que será executado em cada lote.\n",
        "\n",
        "Ligue o `MEAN` e o `STD` ao normalizador fn usando `functools.partial`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UXwEOd5VIhbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = functools.partial(\n",
        "    normalize_numeric_data,\n",
        "    mean=MEAN,\n",
        "    std=STD\n",
        ")"
      ],
      "metadata": {
        "id": "1wQr6HKsp-mS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_column = tf.feature_column.numeric_column('numeric', \n",
        "                                                  normalizer_fn=normalizer,\n",
        "                                                  shape=[len(NUMERIC_FEATURES)])\n",
        "\n",
        "numeric_column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWO50jnkp-i5",
        "outputId": "5524e29b-c071-4397-b37b-27c6b97fcd8d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NumericColumn(key='numeric', shape=(4,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function normalize_numeric_data at 0x7f0c682571f0>, mean=array([29.631,  0.545,  0.38 , 34.385]), std=array([12.512,  1.151,  0.793, 54.598])))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = [numeric_column]"
      ],
      "metadata": {
        "id": "BPgl0kqkp-gp"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao treinar o modelo, inclua esta coluna de característica para selecionar e centralizar este bloco de dados numéricos:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3mivxWFMI3Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch['numeric']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jfHcSTpp-fd",
        "outputId": "0604b260-65cb-4ee3-8663-443fa77226d3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 4), dtype=float32, numpy=\n",
              "array([[ 80.   ,   0.   ,   0.   ,  30.   ],\n",
              "       [ 44.   ,   0.   ,   1.   ,  57.979],\n",
              "       [ 30.   ,   0.   ,   0.   ,  27.75 ],\n",
              "       [ 70.   ,   1.   ,   1.   ,  71.   ],\n",
              "       [ 34.   ,   1.   ,   0.   ,  26.   ],\n",
              "       [ 28.   ,   0.   ,   0.   ,   0.   ],\n",
              "       [ 44.   ,   0.   ,   1.   ,  16.1  ],\n",
              "       [ 28.   ,   0.   ,   0.   ,   0.   ],\n",
              "       [ 28.   ,   0.   ,   0.   ,   7.229],\n",
              "       [ 28.   ,   0.   ,   0.   ,   7.896],\n",
              "       [ 30.   ,   0.   ,   0.   ,  93.5  ],\n",
              "       [ 28.   ,   0.   ,   0.   ,   7.796],\n",
              "       [ 26.   ,   0.   ,   0.   ,   7.896],\n",
              "       [ 22.   ,   0.   ,   2.   ,  49.5  ],\n",
              "       [ 18.   ,   0.   ,   0.   ,  73.5  ],\n",
              "       [ 28.   ,   8.   ,   2.   ,  69.55 ],\n",
              "       [ 28.   ,   0.   ,   0.   ,   7.312],\n",
              "       [ 25.   ,   0.   ,   0.   ,   7.05 ],\n",
              "       [ 25.   ,   1.   ,   0.   ,  17.8  ],\n",
              "       [ 28.   ,   0.   ,   0.   , 227.525],\n",
              "       [ 28.   ,   1.   ,   0.   ,  82.171],\n",
              "       [ 40.   ,   1.   ,   0.   ,   9.475],\n",
              "       [ 21.   ,   0.   ,   0.   ,  77.958],\n",
              "       [ 36.   ,   0.   ,   2.   ,  71.   ],\n",
              "       [ 28.   ,   0.   ,   2.   ,  15.246],\n",
              "       [ 16.   ,   0.   ,   0.   ,  26.   ],\n",
              "       [ 31.   ,   1.   ,   0.   ,  52.   ],\n",
              "       [ 28.   ,   0.   ,   0.   ,  26.55 ],\n",
              "       [ 19.   ,   1.   ,   0.   ,  26.   ],\n",
              "       [ 28.   ,   0.   ,   0.   ,   8.05 ],\n",
              "       [ 58.   ,   0.   ,   0.   , 146.521],\n",
              "       [ 35.   ,   0.   ,   0.   , 512.329],\n",
              "       [ 28.   ,   0.   ,   0.   ,   7.05 ],\n",
              "       [ 38.   ,   0.   ,   0.   , 227.525],\n",
              "       [ 21.   ,   0.   ,   0.   ,  73.5  ],\n",
              "       [ 28.   ,   0.   ,   0.   ,   8.05 ],\n",
              "       [ 18.   ,   0.   ,   0.   ,  11.5  ],\n",
              "       [ 48.   ,   0.   ,   0.   ,  26.55 ],\n",
              "       [ 36.   ,   1.   ,   1.   ,  24.15 ],\n",
              "       [ 18.   ,   0.   ,   0.   ,  13.   ],\n",
              "       [ 19.   ,   0.   ,   0.   ,  30.   ],\n",
              "       [ 24.   ,   2.   ,   0.   ,  73.5  ],\n",
              "       [ 23.   ,   0.   ,   0.   ,   7.925],\n",
              "       [  2.   ,   0.   ,   1.   ,  10.462],\n",
              "       [ 26.   ,   0.   ,   0.   ,   7.925],\n",
              "       [ 27.   ,   1.   ,   0.   ,  53.1  ],\n",
              "       [ 22.   ,   1.   ,   2.   ,  41.579],\n",
              "       [  4.   ,   0.   ,   2.   ,  22.025],\n",
              "       [ 36.   ,   0.   ,   0.   ,  10.5  ],\n",
              "       [  0.75 ,   2.   ,   1.   ,  19.258],\n",
              "       [ 24.   ,   0.   ,   0.   ,  13.   ],\n",
              "       [ 36.   ,   1.   ,   0.   ,  17.4  ],\n",
              "       [ 28.   ,   1.   ,   0.   ,  15.85 ],\n",
              "       [ 43.   ,   1.   ,   1.   ,  26.25 ],\n",
              "       [ 19.   ,   0.   ,   0.   ,  10.5  ],\n",
              "       [ 22.   ,   0.   ,   0.   , 151.55 ],\n",
              "       [ 51.   ,   0.   ,   1.   ,  61.379],\n",
              "       [ 28.   ,   0.   ,   0.   ,   7.733],\n",
              "       [ 28.   ,   0.   ,   0.   ,   7.75 ],\n",
              "       [ 39.   ,   1.   ,   5.   ,  31.275],\n",
              "       [ 28.   ,   0.   ,   2.   ,   7.75 ],\n",
              "       [ 19.   ,   0.   ,   0.   ,   7.775],\n",
              "       [ 18.   ,   0.   ,   0.   ,   7.796],\n",
              "       [ 28.   ,   0.   ,   0.   ,   7.229],\n",
              "       [ 56.   ,   0.   ,   0.   ,  26.55 ],\n",
              "       [ 28.   ,   1.   ,   2.   ,  23.45 ],\n",
              "       [ 62.   ,   0.   ,   0.   ,  10.5  ],\n",
              "       [ 34.   ,   0.   ,   0.   ,  10.5  ],\n",
              "       [ 30.5  ,   0.   ,   0.   ,   8.05 ],\n",
              "       [ 38.   ,   0.   ,   1.   , 153.462],\n",
              "       [ 33.   ,   0.   ,   2.   ,  26.   ],\n",
              "       [ 49.   ,   0.   ,   0.   ,  25.929],\n",
              "       [ 23.   ,   0.   ,   0.   ,  13.   ],\n",
              "       [ 41.   ,   2.   ,   0.   ,  14.108],\n",
              "       [ 25.   ,   1.   ,   0.   ,  91.079],\n",
              "       [ 50.   ,   0.   ,   1.   ,  26.   ],\n",
              "       [ 28.   ,   0.   ,   0.   ,   8.05 ],\n",
              "       [ 58.   ,   0.   ,   1.   , 153.462],\n",
              "       [ 28.   ,   0.   ,   0.   ,   7.25 ],\n",
              "       [ 28.   ,   0.   ,   0.   ,   7.896],\n",
              "       [ 51.   ,   1.   ,   0.   ,  77.958],\n",
              "       [ 24.   ,   0.   ,   1.   , 247.521],\n",
              "       [ 25.   ,   0.   ,   0.   ,   7.742],\n",
              "       [ 33.   ,   0.   ,   0.   ,  12.275],\n",
              "       [ 33.   ,   1.   ,   2.   ,  27.75 ],\n",
              "       [ 38.   ,   0.   ,   0.   ,  13.   ],\n",
              "       [ 30.   ,   0.   ,   0.   ,  13.   ],\n",
              "       [ 28.   ,   0.   ,   0.   ,  52.   ],\n",
              "       [ 34.   ,   0.   ,   0.   ,  26.55 ],\n",
              "       [ 60.   ,   1.   ,   1.   ,  39.   ],\n",
              "       [ 45.   ,   1.   ,   1.   , 164.867],\n",
              "       [ 28.   ,   0.   ,   0.   ,   7.896],\n",
              "       [  5.   ,   2.   ,   1.   ,  19.258],\n",
              "       [ 28.   ,   0.   ,   0.   ,   7.896],\n",
              "       [ 50.   ,   1.   ,   0.   , 106.425],\n",
              "       [ 25.   ,   0.   ,   0.   ,   7.05 ],\n",
              "       [ 28.   ,   1.   ,   0.   ,  15.5  ],\n",
              "       [ 35.   ,   0.   ,   0.   ,   7.896],\n",
              "       [ 20.   ,   0.   ,   0.   ,   8.05 ],\n",
              "       [ 16.   ,   0.   ,   0.   ,   8.05 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "\n",
        "numeric_layer(example_batch).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXBGBdJDp-ec",
        "outputId": "10cd00ae-f50c-47f2-be33-e06077474390"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.026, -0.474, -0.479, -0.08 ],\n",
              "       [ 1.148, -0.474,  0.782,  0.432],\n",
              "       [ 0.029, -0.474, -0.479, -0.122],\n",
              "       [ 3.226,  0.395,  0.782,  0.671],\n",
              "       [ 0.349,  0.395, -0.479, -0.154],\n",
              "       [-0.13 , -0.474, -0.479, -0.63 ],\n",
              "       [ 1.148, -0.474,  0.782, -0.335],\n",
              "       [-0.13 , -0.474, -0.479, -0.63 ],\n",
              "       [-0.13 , -0.474, -0.479, -0.497],\n",
              "       [-0.13 , -0.474, -0.479, -0.485],\n",
              "       [ 0.029, -0.474, -0.479,  1.083],\n",
              "       [-0.13 , -0.474, -0.479, -0.487],\n",
              "       [-0.29 , -0.474, -0.479, -0.485],\n",
              "       [-0.61 , -0.474,  2.043,  0.277],\n",
              "       [-0.93 , -0.474, -0.479,  0.716],\n",
              "       [-0.13 ,  6.476,  2.043,  0.644],\n",
              "       [-0.13 , -0.474, -0.479, -0.496],\n",
              "       [-0.37 , -0.474, -0.479, -0.501],\n",
              "       [-0.37 ,  0.395, -0.479, -0.304],\n",
              "       [-0.13 , -0.474, -0.479,  3.538],\n",
              "       [-0.13 ,  0.395, -0.479,  0.875],\n",
              "       [ 0.829,  0.395, -0.479, -0.456],\n",
              "       [-0.69 , -0.474, -0.479,  0.798],\n",
              "       [ 0.509, -0.474,  2.043,  0.671],\n",
              "       [-0.13 , -0.474,  2.043, -0.351],\n",
              "       [-1.089, -0.474, -0.479, -0.154],\n",
              "       [ 0.109,  0.395, -0.479,  0.323],\n",
              "       [-0.13 , -0.474, -0.479, -0.144],\n",
              "       [-0.85 ,  0.395, -0.479, -0.154],\n",
              "       [-0.13 , -0.474, -0.479, -0.482],\n",
              "       [ 2.267, -0.474, -0.479,  2.054],\n",
              "       [ 0.429, -0.474, -0.479,  8.754],\n",
              "       [-0.13 , -0.474, -0.479, -0.501],\n",
              "       [ 0.669, -0.474, -0.479,  3.538],\n",
              "       [-0.69 , -0.474, -0.479,  0.716],\n",
              "       [-0.13 , -0.474, -0.479, -0.482],\n",
              "       [-0.93 , -0.474, -0.479, -0.419],\n",
              "       [ 1.468, -0.474, -0.479, -0.144],\n",
              "       [ 0.509,  0.395,  0.782, -0.187],\n",
              "       [-0.93 , -0.474, -0.479, -0.392],\n",
              "       [-0.85 , -0.474, -0.479, -0.08 ],\n",
              "       [-0.45 ,  1.264, -0.479,  0.716],\n",
              "       [-0.53 , -0.474, -0.479, -0.485],\n",
              "       [-2.208, -0.474,  0.782, -0.438],\n",
              "       [-0.29 , -0.474, -0.479, -0.485],\n",
              "       [-0.21 ,  0.395, -0.479,  0.343],\n",
              "       [-0.61 ,  0.395,  2.043,  0.132],\n",
              "       [-2.049, -0.474,  2.043, -0.226],\n",
              "       [ 0.509, -0.474, -0.479, -0.437],\n",
              "       [-2.308,  1.264,  0.782, -0.277],\n",
              "       [-0.45 , -0.474, -0.479, -0.392],\n",
              "       [ 0.509,  0.395, -0.479, -0.311],\n",
              "       [-0.13 ,  0.395, -0.479, -0.339],\n",
              "       [ 1.068,  0.395,  0.782, -0.149],\n",
              "       [-0.85 , -0.474, -0.479, -0.437],\n",
              "       [-0.61 , -0.474, -0.479,  2.146],\n",
              "       [ 1.708, -0.474,  0.782,  0.494],\n",
              "       [-0.13 , -0.474, -0.479, -0.488],\n",
              "       [-0.13 , -0.474, -0.479, -0.488],\n",
              "       [ 0.749,  0.395,  5.827, -0.057],\n",
              "       [-0.13 , -0.474,  2.043, -0.488],\n",
              "       [-0.85 , -0.474, -0.479, -0.487],\n",
              "       [-0.93 , -0.474, -0.479, -0.487],\n",
              "       [-0.13 , -0.474, -0.479, -0.497],\n",
              "       [ 2.108, -0.474, -0.479, -0.144],\n",
              "       [-0.13 ,  0.395,  2.043, -0.2  ],\n",
              "       [ 2.587, -0.474, -0.479, -0.437],\n",
              "       [ 0.349, -0.474, -0.479, -0.437],\n",
              "       [ 0.069, -0.474, -0.479, -0.482],\n",
              "       [ 0.669, -0.474,  0.782,  2.181],\n",
              "       [ 0.269, -0.474,  2.043, -0.154],\n",
              "       [ 1.548, -0.474, -0.479, -0.155],\n",
              "       [-0.53 , -0.474, -0.479, -0.392],\n",
              "       [ 0.909,  1.264, -0.479, -0.371],\n",
              "       [-0.37 ,  0.395, -0.479,  1.038],\n",
              "       [ 1.628, -0.474,  0.782, -0.154],\n",
              "       [-0.13 , -0.474, -0.479, -0.482],\n",
              "       [ 2.267, -0.474,  0.782,  2.181],\n",
              "       [-0.13 , -0.474, -0.479, -0.497],\n",
              "       [-0.13 , -0.474, -0.479, -0.485],\n",
              "       [ 1.708,  0.395, -0.479,  0.798],\n",
              "       [-0.45 , -0.474,  0.782,  3.904],\n",
              "       [-0.37 , -0.474, -0.479, -0.488],\n",
              "       [ 0.269, -0.474, -0.479, -0.405],\n",
              "       [ 0.269,  0.395,  2.043, -0.122],\n",
              "       [ 0.669, -0.474, -0.479, -0.392],\n",
              "       [ 0.029, -0.474, -0.479, -0.392],\n",
              "       [-0.13 , -0.474, -0.479,  0.323],\n",
              "       [ 0.349, -0.474, -0.479, -0.144],\n",
              "       [ 2.427,  0.395,  0.782,  0.085],\n",
              "       [ 1.228,  0.395,  0.782,  2.39 ],\n",
              "       [-0.13 , -0.474, -0.479, -0.485],\n",
              "       [-1.969,  1.264,  0.782, -0.277],\n",
              "       [-0.13 , -0.474, -0.479, -0.485],\n",
              "       [ 1.628,  0.395, -0.479,  1.319],\n",
              "       [-0.37 , -0.474, -0.479, -0.501],\n",
              "       [-0.13 ,  0.395, -0.479, -0.346],\n",
              "       [ 0.429, -0.474, -0.479, -0.485],\n",
              "       [-0.77 , -0.474, -0.479, -0.482],\n",
              "       [-1.089, -0.474, -0.479, -0.482]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A normalização baseada em média usada aqui requer conhecer os meios de cada coluna antes do tempo."
      ],
      "metadata": {
        "id": "8fypSOY4I8wD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dados categóricos**\n",
        "\n",
        "Algumas das colunas nos dados CSV são colunas categóricas. Ou seja, o conteúdo deve ser um dentre um conjunto limitado de opções.\n",
        "\n",
        "Use a API `tf.feature_column` para criar uma coleção com uma `tf.feature_column.indicator_column` para cada coluna categórica.\n",
        "\n"
      ],
      "metadata": {
        "id": "CzlWhbF6FMbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORIES = {\n",
        "    'sex': ['male', 'female'],\n",
        "    'class': ['First', 'Second', 'Third'],\n",
        "    'deck': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
        "    'embark_town': ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
        "    'alone': ['y', 'n']\n",
        "}\n",
        "\n",
        "CATEGORIES "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anh-L8Eop-di",
        "outputId": "82f23593-695c-4847-aa8f-40332a4948a2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sex': ['male', 'female'],\n",
              " 'class': ['First', 'Second', 'Third'],\n",
              " 'deck': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
              " 'embark_town': ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
              " 'alone': ['y', 'n']}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "('A B C D E F G H I J').split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-rW-q2mTvzI",
        "outputId": "25b9af08-77e2-4ee9-f457-b532745ce1b5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORIES = {\n",
        "    'sex': ('male female').split(),\n",
        "    'class': ('First Second Third').split(),\n",
        "    'deck': ('A B C D E F G H I J').split(),\n",
        "    'embark_town': ('Cherbourg Southhampton Queenstown').split(),\n",
        "    'alone': ('y n').split()\n",
        "}\n",
        "\n",
        "CATEGORIES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7Bfn-f1p-XK",
        "outputId": "ef1fa2cf-7bd0-4fad-b965-41f5f0756850"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sex': ['male', 'female'],\n",
              " 'class': ['First', 'Second', 'Third'],\n",
              " 'deck': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
              " 'embark_town': ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
              " 'alone': ['y', 'n']}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = []\n",
        "\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab\n",
        "    )\n",
        "\n",
        "    categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
      ],
      "metadata": {
        "id": "h7aue9hBp-U9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g46xafdUp-Px",
        "outputId": "6ace0c8b-8e86-4d8c-a7d3-7ad9fce0f767"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('First', 'Second', 'Third'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Cherbourg', 'Southhampton', 'Queenstown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('y', 'n'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)"
      ],
      "metadata": {
        "id": "-TJUJvpVp-Oi"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(categorical_layer(example_batch).numpy()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypJjjo_Ip-LM",
        "outputId": "9e08d8ad-1c09-442e-880b-1ff60a734c66"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Isso fará parte de uma entrada de processamento de dados posteriormente, quando você construir o modelo.\n",
        "\n"
      ],
      "metadata": {
        "id": "TeC_-NJKJJYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Camada combinada de pré-processamento**\n",
        "\n",
        "Adicione as duas coleções de colunas de recursos e passe-as para um `tf.keras.layers.DenseFeatures` para criar uma camada de entrada que extrairá e pré-processará os dois tipos de entrada:"
      ],
      "metadata": {
        "id": "tJEs4ubkJMa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns + numeric_columns)"
      ],
      "metadata": {
        "id": "OX9W4m7ep-JJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessing_layer(example_batch).numpy()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5UqQicEp-F0",
        "outputId": "50eca6d9-a310-4260-b2a3-3bc304c98290"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.     0.     1.     0.     0.     1.     0.     0.     0.     0.\n",
            "  0.     0.     0.     0.     0.     0.     0.     0.     4.026 -0.474\n",
            " -0.479 -0.08   1.     0.   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4. Construir o modelo**"
      ],
      "metadata": {
        "id": "bdN_rM-bJam5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crie um `tf.keras.Sequential`, começando com o `preprocessing_layer`."
      ],
      "metadata": {
        "id": "GlJaWD8qJm8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    preprocessing_layer, \n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "baPr5J6-p-DJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "uBLhSs-2cmA-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5.Treinar, avaliar, e prever**\n"
      ],
      "metadata": {
        "id": "MZZRvfEyJx5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora o modelo pode ser instanciado e treinado."
      ],
      "metadata": {
        "id": "J9qFrn3eJ5tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = packed_train_data.shuffle(500)\n",
        "test_data = packed_test_data"
      ],
      "metadata": {
        "id": "CdVxIl-2cl_z"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, epochs=20, \n",
        "          validation_data=test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N2mwx6ncl-t",
        "outputId": "36ab3f46-fe08-49fd-d918-e2cff798d6ae"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('sex', <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>), ('class', <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>), ('deck', <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>), ('embark_town', <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>), ('alone', <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>), ('numeric', <tf.Tensor 'IteratorGetNext:4' shape=(None, 4) dtype=float32>)]). Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('sex', <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>), ('class', <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>), ('deck', <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>), ('embark_town', <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>), ('alone', <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>), ('numeric', <tf.Tensor 'IteratorGetNext:4' shape=(None, 4) dtype=float32>)]). Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r      1/Unknown - 4s 4s/step - loss: 0.7131 - accuracy: 0.6400"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('sex', <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>), ('class', <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>), ('deck', <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>), ('embark_town', <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>), ('alone', <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>), ('numeric', <tf.Tensor 'IteratorGetNext:4' shape=(None, 4) dtype=float32>)]). Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 6s 429ms/step - loss: 0.6582 - accuracy: 0.6124 - val_loss: 0.6008 - val_accuracy: 0.6288\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5542 - accuracy: 0.6587 - val_loss: 0.5425 - val_accuracy: 0.7159\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 1s 48ms/step - loss: 0.4926 - accuracy: 0.7464 - val_loss: 0.5038 - val_accuracy: 0.7462\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.4553 - accuracy: 0.7847 - val_loss: 0.4778 - val_accuracy: 0.7727\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 0.4286 - accuracy: 0.8150 - val_loss: 0.4648 - val_accuracy: 0.7879\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 1s 86ms/step - loss: 0.4128 - accuracy: 0.8293 - val_loss: 0.4584 - val_accuracy: 0.7917\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 1s 115ms/step - loss: 0.4048 - accuracy: 0.8262 - val_loss: 0.4559 - val_accuracy: 0.7917\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 1s 87ms/step - loss: 0.3987 - accuracy: 0.8341 - val_loss: 0.4493 - val_accuracy: 0.7917\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 1s 106ms/step - loss: 0.3919 - accuracy: 0.8405 - val_loss: 0.4431 - val_accuracy: 0.7992\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 1s 89ms/step - loss: 0.3872 - accuracy: 0.8373 - val_loss: 0.4382 - val_accuracy: 0.8030\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 1s 60ms/step - loss: 0.3820 - accuracy: 0.8357 - val_loss: 0.4359 - val_accuracy: 0.8106\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 1s 142ms/step - loss: 0.3785 - accuracy: 0.8373 - val_loss: 0.4329 - val_accuracy: 0.8106\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.3754 - accuracy: 0.8421 - val_loss: 0.4311 - val_accuracy: 0.8220\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 0.3723 - accuracy: 0.8421 - val_loss: 0.4337 - val_accuracy: 0.8220\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 1s 96ms/step - loss: 0.3680 - accuracy: 0.8437 - val_loss: 0.4350 - val_accuracy: 0.8144\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.3652 - accuracy: 0.8501 - val_loss: 0.4331 - val_accuracy: 0.8258\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.3653 - accuracy: 0.8357 - val_loss: 0.4277 - val_accuracy: 0.8258\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.3615 - accuracy: 0.8421 - val_loss: 0.4298 - val_accuracy: 0.8333\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.3578 - accuracy: 0.8389 - val_loss: 0.4312 - val_accuracy: 0.8258\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.3560 - accuracy: 0.8501 - val_loss: 0.4383 - val_accuracy: 0.8258\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c683557c0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depois que o modelo é treinado, você pode verificar sua acurácia no conjunto `test_data`."
      ],
      "metadata": {
        "id": "_qKtu3roKD2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "\n",
        "print('\\n\\nTest Loss: {} | Test Accuracy: {}'.format(test_loss, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXQ-ZwiRcl1p",
        "outputId": "138f6027-1fc9-409d-a140-3b4ed31452ca"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4383 - accuracy: 0.8258\n",
            "\n",
            "\n",
            "Test Loss: 0.43833836913108826 | Test Accuracy: 0.8257575631141663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `tf.keras.Model.predict` para inferir rótulos em um lote ou em um conjunto de dados de lotes."
      ],
      "metadata": {
        "id": "xrFwmIaTKKWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_data)\n",
        "\n",
        "for prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\n",
        "    print('Predicted survival: {:.2%}'.format(prediction[0]),\n",
        "          ' | Actual outcome: ',\n",
        "          ('SURVIVED' if bool(survived) else 'DIED'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBt4et0Zclsr",
        "outputId": "be5d6a9d-044c-4c97-a350-888364498cb7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('sex', <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>), ('class', <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>), ('deck', <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>), ('embark_town', <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>), ('alone', <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>), ('numeric', <tf.Tensor 'IteratorGetNext:4' shape=(None, 4) dtype=float32>)]). Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 15ms/step\n",
            "Predicted survival: 42.11%  | Actual outcome:  DIED\n",
            "Predicted survival: 389.54%  | Actual outcome:  DIED\n",
            "Predicted survival: 37.39%  | Actual outcome:  DIED\n",
            "Predicted survival: 29.65%  | Actual outcome:  DIED\n",
            "Predicted survival: -43.78%  | Actual outcome:  SURVIVED\n",
            "Predicted survival: 218.56%  | Actual outcome:  DIED\n",
            "Predicted survival: 161.74%  | Actual outcome:  SURVIVED\n",
            "Predicted survival: -13.55%  | Actual outcome:  SURVIVED\n",
            "Predicted survival: -205.13%  | Actual outcome:  DIED\n",
            "Predicted survival: 139.54%  | Actual outcome:  DIED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "history = model.fit(train_data, epochs=EPOCHS, \n",
        "                    validation_data=test_data)"
      ],
      "metadata": {
        "id": "gTMxlvE4clrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a604f4b-c703-41fe-dbc2-8d3bf22e0b54"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 0.3586 - accuracy: 0.8549 - val_loss: 0.4477 - val_accuracy: 0.8182\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.3560 - accuracy: 0.8453 - val_loss: 0.4345 - val_accuracy: 0.8182\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.3488 - accuracy: 0.8533 - val_loss: 0.4377 - val_accuracy: 0.8144\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.3485 - accuracy: 0.8437 - val_loss: 0.4283 - val_accuracy: 0.8295\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.3464 - accuracy: 0.8437 - val_loss: 0.4314 - val_accuracy: 0.8295\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.3434 - accuracy: 0.8469 - val_loss: 0.4315 - val_accuracy: 0.8333\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.3407 - accuracy: 0.8549 - val_loss: 0.4249 - val_accuracy: 0.8333\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.3384 - accuracy: 0.8517 - val_loss: 0.4258 - val_accuracy: 0.8371\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3361 - accuracy: 0.8517 - val_loss: 0.4276 - val_accuracy: 0.8371\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - 1s 55ms/step - loss: 0.3329 - accuracy: 0.8485 - val_loss: 0.4361 - val_accuracy: 0.8447\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - 1s 55ms/step - loss: 0.3328 - accuracy: 0.8565 - val_loss: 0.4288 - val_accuracy: 0.8409\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.3302 - accuracy: 0.8549 - val_loss: 0.4274 - val_accuracy: 0.8371\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.3272 - accuracy: 0.8596 - val_loss: 0.4357 - val_accuracy: 0.8561\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.3276 - accuracy: 0.8581 - val_loss: 0.4294 - val_accuracy: 0.8409\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.3240 - accuracy: 0.8565 - val_loss: 0.4311 - val_accuracy: 0.8409\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.3226 - accuracy: 0.8549 - val_loss: 0.4343 - val_accuracy: 0.8409\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.3216 - accuracy: 0.8533 - val_loss: 0.4327 - val_accuracy: 0.8447\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3231 - accuracy: 0.8549 - val_loss: 0.4398 - val_accuracy: 0.8485\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3195 - accuracy: 0.8596 - val_loss: 0.4337 - val_accuracy: 0.8409\n",
            "Epoch 20/30\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.3169 - accuracy: 0.8612 - val_loss: 0.4332 - val_accuracy: 0.8409\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3147 - accuracy: 0.8612 - val_loss: 0.4430 - val_accuracy: 0.8485\n",
            "Epoch 22/30\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3157 - accuracy: 0.8612 - val_loss: 0.4346 - val_accuracy: 0.8447\n",
            "Epoch 23/30\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3122 - accuracy: 0.8581 - val_loss: 0.4349 - val_accuracy: 0.8447\n",
            "Epoch 24/30\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.3099 - accuracy: 0.8612 - val_loss: 0.4391 - val_accuracy: 0.8485\n",
            "Epoch 25/30\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.3069 - accuracy: 0.8612 - val_loss: 0.4331 - val_accuracy: 0.8447\n",
            "Epoch 26/30\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.3060 - accuracy: 0.8581 - val_loss: 0.4365 - val_accuracy: 0.8447\n",
            "Epoch 27/30\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.3034 - accuracy: 0.8644 - val_loss: 0.4374 - val_accuracy: 0.8447\n",
            "Epoch 28/30\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3036 - accuracy: 0.8676 - val_loss: 0.4528 - val_accuracy: 0.8409\n",
            "Epoch 29/30\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3050 - accuracy: 0.8692 - val_loss: 0.4484 - val_accuracy: 0.8333\n",
            "Epoch 30/30\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2998 - accuracy: 0.8660 - val_loss: 0.4374 - val_accuracy: 0.8485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "id": "5kacjnzIclqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29a2d96-99ab-44f6-dc05-b04c1a8dca59"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.35856133699417114,\n",
              "  0.3559688925743103,\n",
              "  0.34880802035331726,\n",
              "  0.3484901487827301,\n",
              "  0.3464476764202118,\n",
              "  0.3434212803840637,\n",
              "  0.340709924697876,\n",
              "  0.33842673897743225,\n",
              "  0.3361249268054962,\n",
              "  0.33291274309158325,\n",
              "  0.33280953764915466,\n",
              "  0.3302273154258728,\n",
              "  0.32722121477127075,\n",
              "  0.327571839094162,\n",
              "  0.32401394844055176,\n",
              "  0.3226124048233032,\n",
              "  0.3216422200202942,\n",
              "  0.32308298349380493,\n",
              "  0.31950703263282776,\n",
              "  0.31691327691078186,\n",
              "  0.3146587610244751,\n",
              "  0.3156889081001282,\n",
              "  0.3121761679649353,\n",
              "  0.3099035620689392,\n",
              "  0.3068755567073822,\n",
              "  0.30603280663490295,\n",
              "  0.3033793270587921,\n",
              "  0.3035846948623657,\n",
              "  0.3050065338611603,\n",
              "  0.29981759190559387],\n",
              " 'accuracy': [0.8548644185066223,\n",
              "  0.8452950716018677,\n",
              "  0.8532695174217224,\n",
              "  0.8437001705169678,\n",
              "  0.8437001705169678,\n",
              "  0.8468899726867676,\n",
              "  0.8548644185066223,\n",
              "  0.8516746163368225,\n",
              "  0.8516746163368225,\n",
              "  0.8484848737716675,\n",
              "  0.8564593195915222,\n",
              "  0.8548644185066223,\n",
              "  0.859649121761322,\n",
              "  0.8580542206764221,\n",
              "  0.8564593195915222,\n",
              "  0.8548644185066223,\n",
              "  0.8532695174217224,\n",
              "  0.8548644185066223,\n",
              "  0.859649121761322,\n",
              "  0.8612440228462219,\n",
              "  0.8612440228462219,\n",
              "  0.8612440228462219,\n",
              "  0.8580542206764221,\n",
              "  0.8612440228462219,\n",
              "  0.8612440228462219,\n",
              "  0.8580542206764221,\n",
              "  0.8644338250160217,\n",
              "  0.8676236271858215,\n",
              "  0.8692185282707214,\n",
              "  0.8660287261009216],\n",
              " 'val_loss': [0.44773069024086,\n",
              "  0.4345032572746277,\n",
              "  0.4377215504646301,\n",
              "  0.4283280670642853,\n",
              "  0.43142613768577576,\n",
              "  0.431497186422348,\n",
              "  0.42491862177848816,\n",
              "  0.42583274841308594,\n",
              "  0.42764362692832947,\n",
              "  0.4360730051994324,\n",
              "  0.4287900924682617,\n",
              "  0.42737147212028503,\n",
              "  0.43569159507751465,\n",
              "  0.4294346272945404,\n",
              "  0.43106594681739807,\n",
              "  0.43425583839416504,\n",
              "  0.43267592787742615,\n",
              "  0.4397721290588379,\n",
              "  0.4337124228477478,\n",
              "  0.4332468807697296,\n",
              "  0.4430203437805176,\n",
              "  0.43464553356170654,\n",
              "  0.4349151849746704,\n",
              "  0.4390539824962616,\n",
              "  0.4330604374408722,\n",
              "  0.4364880621433258,\n",
              "  0.43737566471099854,\n",
              "  0.45277756452560425,\n",
              "  0.4483729600906372,\n",
              "  0.4374234080314636],\n",
              " 'val_accuracy': [0.8181818127632141,\n",
              "  0.8181818127632141,\n",
              "  0.814393937587738,\n",
              "  0.8295454382896423,\n",
              "  0.8295454382896423,\n",
              "  0.8333333134651184,\n",
              "  0.8333333134651184,\n",
              "  0.8371211886405945,\n",
              "  0.8371211886405945,\n",
              "  0.8446969985961914,\n",
              "  0.8409090638160706,\n",
              "  0.8371211886405945,\n",
              "  0.8560606241226196,\n",
              "  0.8409090638160706,\n",
              "  0.8409090638160706,\n",
              "  0.8409090638160706,\n",
              "  0.8446969985961914,\n",
              "  0.8484848737716675,\n",
              "  0.8409090638160706,\n",
              "  0.8409090638160706,\n",
              "  0.8484848737716675,\n",
              "  0.8446969985961914,\n",
              "  0.8446969985961914,\n",
              "  0.8484848737716675,\n",
              "  0.8446969985961914,\n",
              "  0.8446969985961914,\n",
              "  0.8446969985961914,\n",
              "  0.8409090638160706,\n",
              "  0.8333333134651184,\n",
              "  0.8484848737716675]}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "id": "_8BI6pW_clpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e995b5f-ae19-4c95-8adc-4b91d0378ece"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instanciando as métricas do modelo\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "metadata": {
        "id": "iz1vQI2xRRu3"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "metadata": {
        "id": "i8NNmPV2BK3L"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotando o gráfico \n",
        "plt.figure(figsize=(16, 9))\n",
        "\n",
        "plt.plot(range(EPOCHS), accuracy, 'r', label='Training Accuracy')\n",
        "plt.plot(range(EPOCHS), val_accuracy, 'orange', \n",
        "         label='Validation Accuracy')\n",
        "\n",
        "plt.plot(range(EPOCHS), loss, 'b', label='Training Loss')\n",
        "plt.plot(range(EPOCHS), val_loss, 'g', \n",
        "         label='Validation Loss')\n",
        "\n",
        "plt.legend(loc='best')    # lower left, lower right, upper left, upper rigth, best, center\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.title('Training & Validation\\n', size=20)\n",
        "plt.xlabel('epochs', size=16)\n",
        "plt.ylabel('accuracy', size=16)\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "rNVjTym4RRsJ",
        "outputId": "5952df87-a25c-4f02-8fc9-709bb5764255"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizando as variáveis local do ambiente\n",
        "%whos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_Rm8RObAB4k",
        "outputId": "34920b73-b9fb-4657-dc16-016c63ec0a29"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable                 Type                               Data/Info\n",
            "---------------------------------------------------------------------\n",
            "CATEGORIES               dict                               n=5\n",
            "CSV_COLMUNS              list                               n=10\n",
            "DEFAULTS                 list                               n=5\n",
            "EPOCHS                   int                                30\n",
            "LABELS                   list                               n=2\n",
            "LABEL_COLUMN             str                                survived\n",
            "MEAN                     ndarray                            4: 4 elems, type `float64`, 32 bytes\n",
            "NUMERIC_FEATURES         list                               n=4\n",
            "PackNumericFeatures      type                               <class '__main__.PackNumericFeatures'>\n",
            "SELECT_COLUMNS           list                               n=5\n",
            "STD                      ndarray                            4: 4 elems, type `float64`, 32 bytes\n",
            "TEST_DATA_URL            str                                https://storage.googleapi<...>datasets/titanic/eval.csv\n",
            "TRAIN_DATA_URL           str                                https://storage.googleapi<...>atasets/titanic/train.csv\n",
            "absolute_import          _Feature                           _Feature((2, 5, 0, 'alpha<...>, 0, 'alpha', 0), 262144)\n",
            "accuracy                 list                               n=30\n",
            "cat_col                  VocabularyListCategoricalColumn    VocabularyListCategorical<...>ue=-1, num_oov_buckets=0)\n",
            "categorical_columns      list                               n=5\n",
            "categorical_layer        DenseFeatures                      <keras.feature_column.den<...>object at 0x7f0c682a53a0>\n",
            "desc                     DataFrame                                        age  n_sibl<...>0    5.000000  512.329200\n",
            "division                 _Feature                           _Feature((2, 2, 0, 'alpha<...>, 0, 'alpha', 0), 131072)\n",
            "example_batch            OrderedDict                        OrderedDict([('sex', <tf.<...>05 ]], dtype=float32)>)])\n",
            "feature                  str                                alone\n",
            "features                 EagerTensor                        tf.Tensor(\\n[[ 28.      3<...>=(100, 4), dtype=float32)\n",
            "functools                module                             <module 'functools' from <...>/python3.8/functools.py'>\n",
            "get_dataset              function                           <function get_dataset at 0x7f0c6a9b2a60>\n",
            "history                  History                            <keras.callbacks.History <...>object at 0x7f0c5871c820>\n",
            "labels                   EagerTensor                        tf.Tensor(\\n[0 0 1 1 0 0 <...>hape=(100,), dtype=int32)\n",
            "labels_batch             EagerTensor                        tf.Tensor(\\n[1 1 0 0 0 0 <...>hape=(100,), dtype=int32)\n",
            "loss                     list                               n=30\n",
            "model                    Sequential                         <keras.engine.sequential.<...>object at 0x7f0c682325b0>\n",
            "normalize_numeric_data   function                           <function normalize_numer<...>c_data at 0x7f0c682571f0>\n",
            "normalizer               partial                            functools.partial(<functi<...> 1.151,  0.793, 54.598]))\n",
            "np                       module                             <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
            "numeric_column           NumericColumn                      NumericColumn(key='numeri<...>1.151,  0.793, 54.598])))\n",
            "numeric_columns          list                               n=1\n",
            "numeric_layer            DenseFeatures                      <keras.feature_column.den<...>object at 0x7f0c68288400>\n",
            "pack                     function                           <function pack at 0x7f0c68344f70>\n",
            "packed_dataset           MapDataset                         <MapDataset element_spec=<...>pe=tf.int32, name=None))>\n",
            "packed_test_data         MapDataset                         <MapDataset element_spec=<...>pe=tf.int32, name=None))>\n",
            "packed_train_data        MapDataset                         <MapDataset element_spec=<...>pe=tf.int32, name=None))>\n",
            "pd                       module                             <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
            "plt                      module                             <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
            "prediction               ndarray                            1: 1 elems, type `float32`, 4 bytes\n",
            "predictions              ndarray                            264x1: 264 elems, type `float32`, 1056 bytes\n",
            "preprocessing_layer      DenseFeatures                      <keras.feature_column.den<...>object at 0x7f0c6832c850>\n",
            "print_function           _Feature                           _Feature((2, 6, 0, 'alpha<...> 0, 'alpha', 0), 1048576)\n",
            "raw_test_data            PrefetchDataset                    <PrefetchDataset element_<...>pe=tf.int32, name=None))>\n",
            "raw_train_data           PrefetchDataset                    <PrefetchDataset element_<...>pe=tf.int32, name=None))>\n",
            "show_batch               function                           <function show_batch at 0x7f0c683980d0>\n",
            "survived                 EagerTensor                        tf.Tensor(0, shape=(), dtype=int32)\n",
            "temp_dataset             PrefetchDataset                    <PrefetchDataset element_<...>pe=tf.int32, name=None))>\n",
            "test_accuracy            float                              0.8257575631141663\n",
            "test_data                MapDataset                         <MapDataset element_spec=<...>pe=tf.int32, name=None))>\n",
            "test_file_path           str                                /root/.keras/datasets/eval.csv\n",
            "test_loss                float                              0.43833836913108826\n",
            "tf                       module                             <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
            "train_data               ShuffleDataset                     <ShuffleDataset element_s<...>pe=tf.int32, name=None))>\n",
            "train_file_path          str                                /root/.keras/datasets/train.csv\n",
            "unicode_literals         _Feature                           _Feature((2, 6, 0, 'alpha<...> 0, 'alpha', 0), 2097152)\n",
            "val_accuracy             list                               n=30\n",
            "val_loss                 list                               n=30\n",
            "vocab                    list                               n=2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizando as variáveis local do ambiente em formato de lista\n",
        "%who_ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpgZFzuwAB29",
        "outputId": "01987de4-65b4-4ed2-cff5-550e2c492f71"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CATEGORIES',\n",
              " 'CSV_COLMUNS',\n",
              " 'DEFAULTS',\n",
              " 'EPOCHS',\n",
              " 'LABELS',\n",
              " 'LABEL_COLUMN',\n",
              " 'MEAN',\n",
              " 'NUMERIC_FEATURES',\n",
              " 'PackNumericFeatures',\n",
              " 'SELECT_COLUMNS',\n",
              " 'STD',\n",
              " 'TEST_DATA_URL',\n",
              " 'TRAIN_DATA_URL',\n",
              " 'absolute_import',\n",
              " 'accuracy',\n",
              " 'cat_col',\n",
              " 'categorical_columns',\n",
              " 'categorical_layer',\n",
              " 'desc',\n",
              " 'division',\n",
              " 'example_batch',\n",
              " 'feature',\n",
              " 'features',\n",
              " 'functools',\n",
              " 'get_dataset',\n",
              " 'history',\n",
              " 'labels',\n",
              " 'labels_batch',\n",
              " 'loss',\n",
              " 'model',\n",
              " 'normalize_numeric_data',\n",
              " 'normalizer',\n",
              " 'np',\n",
              " 'numeric_column',\n",
              " 'numeric_columns',\n",
              " 'numeric_layer',\n",
              " 'pack',\n",
              " 'packed_dataset',\n",
              " 'packed_test_data',\n",
              " 'packed_train_data',\n",
              " 'pd',\n",
              " 'plt',\n",
              " 'prediction',\n",
              " 'predictions',\n",
              " 'preprocessing_layer',\n",
              " 'print_function',\n",
              " 'raw_test_data',\n",
              " 'raw_train_data',\n",
              " 'show_batch',\n",
              " 'survived',\n",
              " 'temp_dataset',\n",
              " 'test_accuracy',\n",
              " 'test_data',\n",
              " 'test_file_path',\n",
              " 'test_loss',\n",
              " 'tf',\n",
              " 'train_data',\n",
              " 'train_file_path',\n",
              " 'unicode_literals',\n",
              " 'val_accuracy',\n",
              " 'val_loss',\n",
              " 'vocab']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pp8qSASVAB1q"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ROeY7a00ABxc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAJTzAquABvI"
      },
      "execution_count": 67,
      "outputs": []
    }
  ]
}